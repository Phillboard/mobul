ACE Engage Direct Mail Platform – Technical Reference
1. Architectural Overview
ACE Engage is a direct mail automation platform built to seamlessly integrate with existing systems via a robust API-first architecture[1]. The platform is multi-tenant by design, supporting an internal operations team (Org Admins), partner agencies, and end-client users in a single system. Key architectural components include:
* Frontend: A modern single-page web application (SPA) with a clean B2B SaaS UI, built for responsiveness and ease of use. It provides module-based navigation (Campaigns, Audiences, Analytics, etc.) and role-specific views (Org, Agency, Client)[2][3].
* Backend: A cloud-backed service with a centralized PostgreSQL database and serverless Edge Functions for business logic. All functionality is exposed through RESTful API endpoints that the frontend and external systems consume. This API-centric approach allows external CRMs or software (e.g. HubSpot or custom apps) to work side-by-side with ACE Engage via public APIs and webhooks[1].
* Authentication & Security: The platform uses secure email/password authentication and multi-role access control with Row-Level Security (RLS) at the database level. Each request’s access is constrained to the tenant’s data by server-enforced policies. Secrets (e.g. third-party API keys) are stored securely in the backend, never exposed to clients[4].
* Multi-Tenancy: Organizations and clients are logically separated. Internal users (Org Admins) can access all data, whereas agency and client users are limited to their own organization’s or campaign’s data[3]. The data model includes Organizations (which can be of type “internal” or “agency”) and Clients (the end businesses, each linked to an agency or to the internal org)[5]. Users are linked to one or more clients/agencies via mapping tables. This ensures a single platform instance serves many clients with strict data isolation.
* External Integrations: ACE Engage integrates with external services for direct mail fulfillment and data enrichment. For mailing, it is designed to connect to certified print/mail vendors (like Lob, Stannp, Click2Mail) through API calls[6]. For data, it provides a Lead Marketplace to purchase prospect lists, and can integrate with third-party lead providers. Real-time webhooks are used to notify external systems (e.g. CRMs) of important events (mail delivered, response received), enabling closed-loop integration.
* Scalability & Performance: The architecture supports large mail campaigns (audiences of 100k+ contacts) by streaming data processing and batch operations. Heavy tasks (file parsing, PDF generation, barcode generation, etc.) run in asynchronous serverless functions to keep the app responsive. Key database indexes (e.g. on recipient tokens and campaign status) are in place to optimize query performance[7]. A soft delete with periodic cleanup is implemented to manage data growth (old events and personal data can be purged or anonymized after retention periods)[8].
* Diagram – High-Level Architecture: Clients (browsers) connect to the ACE Engage frontend (React SPA). The SPA communicates via HTTPS to ACE Engage’s REST API (serverless functions). The backend functions interact with the PostgreSQL database (with RLS enforcement) and call out to external services (print vendor APIs, lead data providers). Events from mail tracking and user interactions are recorded in the database. Optionally, ACE Engage sends out webhook POST requests to client-defined endpoints for real-time event notifications.
2. System Modules Overview
ACE Engage’s functionality is organized into several core modules, each accessible via the main navigation. Role-based access governs which modules a user can see and interact with (e.g. only Org Admins see global settings). The primary modules include:
* Dashboard/Analytics: The landing module presenting high-level metrics and trends across campaigns. It shows key performance indicators (KPIs) such as active campaigns, total recipients mailed, delivery rates, response rates, etc., with visualizations (charts, graphs)[9][10]. Org Admins might see an aggregate dashboard across all clients, while a client user sees only their own campaigns. The dashboard provides an at-a-glance ROI view and recent activity feed (e.g. recent campaigns, recent responses) to highlight the platform’s value in driving returns.
* Campaigns: This module encompasses end-to-end campaign management for direct mail. Users can create new direct mail campaigns through a multi-step wizard (select template, audience, mail options, landing page/PURL configuration)[11][12]. Each campaign record links a marketing template (postcard/letter design) with an audience list. The Campaigns section also lists all campaigns with their status (Draft, Proofed, In Production, Mailed, Completed)[13]. Within this module, users can generate proofs, approve campaigns, submit them to print vendors, and then monitor status. There is also access to related sub-pages like Templates Library (for managing mail piece designs) and Batches (for viewing print batch statuses)[6]. Role-based rules: an Agency Admin might see campaigns grouped by client, whereas a Client User sees only their campaigns.
* Audiences (Contacts): This module handles audience and contact list management – essentially the recipients of mailings. Users can import contact lists (CSV/XLSX upload), manage and clean the data, and organize contacts into Audiences[14][15]. The Audiences page provides tools to import leads, view saved lists, segment them, and even purchase new lead lists via the Marketplace (see below). Each Audience record includes metadata like source (imported, purchased, or manually entered)[16], counts of total and valid addresses, and status (e.g. Processing, Ready)[16]. Users can drill down to view and search individual recipients in a list (with pagination), filter by validity or other tags[17], export lists, or delete audiences. Data hygiene features mark invalid or duplicate addresses during import, and suppression filters weed out addresses that should not be mailed (e.g. previous returns or opt-outs). This module ensures that campaigns start with high-quality, targeted mailing lists – a critical factor for ROI as noted in stakeholder discussions.
* Lead Marketplace: (Accessible as a tab or sub-section of Audiences) Provides an interface for users to buy targeted lead lists directly from within ACE Engage. Users can choose an industry vertical (e.g. Roofing, Real Estate Investors, Automotive) and apply filters (e.g. demographic or property-based criteria) to specify the type of prospects they want[18][19]. The Marketplace UI walks through steps: select vertical, set filters, define geographic region (by ZIP, radius, etc.), and choose a quantity of leads. A pricing estimate is shown (e.g. $0.15 per lead) and the user can proceed to purchase[20]. Upon purchase, the system generates a new Audience populated with the leads that match the criteria (the MVP uses a mock data generator to create realistic contacts using the filters)[21][22]. The lead purchase is recorded (for billing or audit) and the audience is immediately available for campaign use. Note: In the current design, this is implemented as a mock integration – real vendor APIs and payment (Stripe) can be enabled later[23][24].
* Analytics & Tracking: Beyond the dashboard, the platform offers detailed campaign analytics pages and tracking tools. Each campaign has an Analytics view showing delivery statistics and engagement metrics (mail delivery timeline, QR/PURL hits, form submissions, conversion rates, etc.)[25][26]. There are interactive charts (e.g. line chart of mail delivered vs. responses over time[27]) and maps/tables highlighting geographic hotspots of engagement[28]. The Tracking sub-module includes real-time tracking of mail pieces and responses at the recipient level, often presented as tables or timelines (e.g. a table of all recipients with last event: Delivered, Scanned, Responded)[29]. Admin users can also access Suppression Lists (addresses never to mail) and other compliance data here or in Settings. Overall, this module closes the loop from sending mail to capturing responses.
* API & Integrations: ACE Engage is built API-first, so there is a dedicated section for API access and integration settings. Here, developers can obtain their client’s API key, see documentation, and manage webhooks. The API key allows external systems to call ACE Engage’s REST endpoints (with Bearer token auth) to import audiences, trigger campaigns, or pull analytics[30]. The UI may present a “Developers” or “Integrations” page with interactive API docs (Swagger/Redoc) and code examples[31][32]. Webhooks can be configured so that ACE will POST event notifications (e.g. when mail is delivered or a lead form is submitted) to a URL the client provides[33]. In this module, users (typically Org or Agency admins) can add webhook endpoints, select which events to subscribe to, generate a signing secret, and view delivery logs[34][35]. Integration settings for print vendors or lead providers (API endpoints and API keys for those services) might also reside here[6]. This module ensures ACE Engage can extend and slot into an existing martech stack rather than operate in isolation.
* Settings & Administration: A module for configuration and administrative functions. It includes User Management (inviting users, assigning roles to client accounts), Organization/Client settings (branding info like logos or brand colors[5][36], time zone preferences, etc.), and Compliance settings (suppression lists, audit logs, data retention rules). For internal Org Admins, this section may expose platform-wide settings such as managing vendor integrations (activating a print vendor from the pre-seeded list[6]), adjusting lead pricing, or reviewing audit logs of user actions for security compliance[37][38]. Audit trails (who exported data, who deleted a campaign, etc.) are recorded in the database[39] and shown here for SOC2/GDPR compliance. Role-based navigation ensures that only authorized roles see the appropriate settings (e.g. Agency Admins might see settings for their agency and clients, while Client Users have a limited or no Settings view beyond their profile).
Each module above works in concert as part of the campaign lifecycle, from data ingestion (Audiences) to execution (Campaigns) to analysis (Analytics), with supporting infrastructure for extensibility (API/Integrations) and governance (Settings/Admin).
3. Database Schema Definitions
ACE Engage’s database uses a relational model (PostgreSQL) with a schema that reflects the multi-tenant structure and direct mail domain logic. Below is a detailed breakdown of the key tables and their columns. All tables enforce appropriate primary keys (usually UUIDs) and foreign keys for referential integrity. Additionally, most tables include standard metadata like created_at, and many support soft deletion via a deleted_at column (for data retention policies)[40].
Tenant & User Tables: These tables manage organizations, clients, and user roles.
* organizations – Master list of organizations (internal operational org, and partner agencies).
Columns: id UUID PK, name TEXT, type TEXT (enum: 'internal' | 'agency'), created_at TIMESTAMPTZ, settings_json JSONB (arbitrary org-specific settings/config)[5].
Usage: Defines top-level tenants. Internal org holds platform owners; each agency org can have multiple client companies.
* clients – End-client businesses that run direct mail campaigns.
Columns: id UUID PK, org_id UUID FK → organizations, name TEXT, industry TEXT (e.g. 'roofing' | 'rei' | 'auto_service' | ...), timezone TEXT, logo_url TEXT, brand_colors_json JSONB, api_key_hash TEXT, created_at TIMESTAMPTZ[5][36].
Usage: Each client belongs to an organization (usually an agency, or the internal org for direct clients). api_key_hash stores a hashed API key for the client’s external API access[41].
* profiles – User profile details, extending auth user accounts.
Columns: id UUID PK (matches the user’s auth ID), email TEXT, full_name TEXT, phone TEXT, timezone TEXT (default 'America/New_York'), created_at TIMESTAMPTZ[42][43].
Usage: Stores user info and preferences. A database trigger auto-creates a profile entry whenever a new user registers (copying their auth user ID and email)[44][45].
* user_roles – Assigns application roles to users.
Columns: id UUID PK, user_id UUID FK → profiles (or auth.users), role app_role ENUM('org_admin','agency_admin','client_user'), created_at TIMESTAMPTZ, UNIQUE(user_id, role)[43][46].
Usage: A user can have multiple roles (e.g. an internal team member might also be an agency_admin for testing). Roles determine access scope. Org Admin = internal ops with full access; Agency Admin = manages campaigns for multiple clients in their org; Client User = manages campaigns for their own company[47]. Role-based Row-Level Security policies on data tables consult this table via a has_role() function to grant access[48][49].
* org_members – Many-to-many link of users to organizations (with an assigned role in that org).
Columns: org_id UUID FK → organizations, user_id UUID FK → profiles, role ENUM('org_admin','agency_admin').
Usage: Indicates which users belong to an organization and at what level. For instance, a user could be an agency_admin of a specific agency org. (Client-level roles are handled by client_users table below; org_members is mainly for internal/agency relationships).
* client_users – Links users to client accounts.
Columns: client_id UUID FK → clients, user_id UUID FK → profiles. (Often the combination is unique.)
Usage: Assigns which client(s) a user can access. For example, an Agency user might be linked to multiple client companies they oversee, or a Client user is linked to their own company’s client record. The platform checks this table (and user_roles) to filter visible campaigns and data[3].
Security: All the above tables have RLS policies so that, for example, client_users and campaign data are only visible to users mapped to those clients, unless the user has an org_admin role that permits broader access[48]. The app_role enum and has_role(uid, role) function support these policies[46][48]. Also, note that authentication is handled by a separate auth.users table (not shown here) provided by the auth system; profiles.id references that.
Campaign & Content Tables: These tables define mail templates and campaigns, and link to audiences and print batches.
   * templates – Library of direct mail piece designs (postcards, letters, etc.).
Columns: id UUID PK, client_id UUID FK → clients, name TEXT, size TEXT (enum of standard sizes, e.g. '4x6' | '6x9' | '6x11' | 'letter' | 'trifold'), industry_vertical TEXT (e.g. roofing, auto for categorization), json_layers JSONB, thumbnail_url TEXT, created_at TIMESTAMPTZ, updated_at TIMESTAMPTZ[50][51].
Usage: Stores the content/design of mail pieces. In MVP, json_layers holds a structured description of template elements (for future drag-and-drop editor)[52]. Templates are tied to a single client for now. This table enables reusing designs across campaigns.
   * audiences – Mailing lists or groups of recipients.
Columns: id UUID PK, client_id UUID FK → clients, name TEXT, source TEXT (enum: 'import' | 'purchase' | 'manual'), total_count INT, valid_count INT, invalid_count INT, hygiene_json JSONB, suppressed_json JSONB, created_at TIMESTAMPTZ, status TEXT (enum: 'processing' | 'ready' | 'failed')[16].
Usage: Represents a set of recipients (e.g. an imported list named “Spring Campaign List”). The counts and status are updated when an import or lead purchase is processed. hygiene_json and suppressed_json can store summary info about any data cleaning (e.g. how many duplicates removed, how many suppressed addresses matched) and suppression actions. When a CSV import is started, an audience is created with status processing and counts updating as validation completes; once done, status becomes ready or failed if errors[16].
   * recipients – Individuals or addresses to mail (members of an audience).
Columns: id UUID PK, audience_id UUID FK → audiences, first_name TEXT, last_name TEXT, company TEXT, address1 TEXT, address2 TEXT, city TEXT, state TEXT, zip TEXT, zip4 TEXT, email TEXT, phone TEXT, token TEXT UNIQUE, geocode_json JSONB, validation_status TEXT (enum: 'valid' | 'invalid' | 'suppressed'), validation_details_json JSONB, created_at TIMESTAMPTZ.
Usage: Each row is a mailing recipient. The token is a unique code for that recipient used to generate PURLs/QR codes[53]. validation_status indicates if the address passed basic validation or was deemed undeliverable (invalid) or was suppressed (e.g. on a do-not-mail list). validation_details_json may contain parse errors or reasons an address is invalid. geocode_json could store latitude/longitude or other geo-demo info if addresses are geocoded, enabling location-based analytics (e.g. mapping responses by city/state). This table can grow large (thousands of recipients per campaign), so inserts are done in batches and indices are added on frequently queried fields like token and audience_id for performance[7].
   * campaigns – Core table tying together a direct mail campaign.
Columns: id UUID PK, client_id UUID FK → clients, audience_id UUID FK → audiences, template_id UUID FK → templates, name TEXT, size TEXT (mail piece size, copied from template but can override), postage TEXT (e.g. 'first_class' | 'standard'), vendor TEXT (which print vendor service is used), lp_mode TEXT (landing page mode: 'bridge' | 'redirect'), base_lp_url TEXT, utm_source TEXT, utm_medium TEXT, utm_campaign TEXT, status TEXT (enum: 'draft' | 'proofed' | 'approved' | 'in_production' | 'mailed' | 'completed'), mail_date DATE, created_at TIMESTAMPTZ, updated_at TIMESTAMPTZ, created_by_user_id UUID FK → profiles.
Usage: Each campaign is a mailing project, linking one audience (who to mail) with one template (what to mail). Key configuration includes postage class and scheduled mail date. The lp_mode and base_lp_url govern how Personalized URLs (PURLs) work: in redirect mode, recipients who visit their PURL are redirected to an external URL (specified in base_lp_url with UTM parameters); in bridge mode, they see a hosted landing page (bridging offline mail to an online lead form)[54][55]. The UTM fields allow dynamic tagging of traffic (defaults provided, e.g. utm_source='directmail')[56]. Campaign status tracks its stage in the lifecycle – newly created campaigns start as draft, then move to proofed after PURLs/QR codes are generated, approved once a user approves the proof, in_production after submission to print, mailed when printing/mailing is completed, and finally completed after the campaign has run its course[13]. (Statuses beyond in_production may be updated automatically via tracking events or manually when a campaign is closed out.)
   * print_batches – Records batches of mail sent to print, especially for large campaigns.
Columns: id UUID PK, campaign_id UUID FK → campaigns, vendor TEXT, batch_number INT, pdf_url TEXT, recipient_count INT, status TEXT (enum: 'pending' | 'printing' | 'mailed' | 'delivered'), created_at TIMESTAMPTZ, updated_at TIMESTAMPTZ.
Usage: When a campaign is submitted to a print vendor, one or more batches are created. For example, a campaign of 50,000 postcards might be split into 5 batches of 10,000 each. Each batch tracks the vendor handling it, a reference or PDF proof URL (if available), how many recipients are in that batch, and its current status in the print pipeline[57]. Initially a batch is pending/printing; once mailed it becomes mailed. If delivery tracking is integrated, eventually it could mark delivered when all pieces in that batch have been confirmed delivered. ACE Engage can display batch status and allow users to drill into batch details (e.g. for reprints or tracking).
Tracking & Attribution Tables: These tables capture events (mail tracking, scans, responses), manage suppressions, and optionally store leads from forms.
      * events – A log of notable events for mail pieces and responses.
Columns: id UUID PK, campaign_id UUID FK → campaigns, recipient_id UUID FK → recipients, event_type TEXT, event_data_json JSONB, occurred_at TIMESTAMPTZ, source TEXT (e.g. 'usps' | 'qr' | 'purl' | 'form' | 'external').[58]
Usage: This is a unified event log for all tracking and conversion events. For mail delivery tracking, typical event_type values include: imb_injected (mail piece entered USPS), imb_in_transit, imb_out_for_delivery, imb_delivered, and mail_returned (if the mail was undeliverable and returned)[59]. These would have source='usps' and might store details like timestamps or scan location in event_data_json. For digital interactions, events like qr_scanned (someone scanned the QR code), purl_viewed (their browser hit the PURL), form_submitted (they submitted the lead form), or call_clicked (clicked a phone number on the page) are recorded – these typically have source 'qr', 'purl', 'form' respectively[58][60]. Each event records the timestamp and any relevant data (e.g. for a form submission, the form field inputs are saved in event_data_json[61][62]). Events are used to power analytics (counts and timelines) and trigger webhooks. They also support recipient-level tracking (so the system can show, for a given recipient, whether they received the mail, opened the link, responded, etc.).
      * suppressed_addresses – A suppression list of addresses that should not be mailed.
Columns: id UUID PK, client_id UUID FK → clients, address1 TEXT, city TEXT, state TEXT, zip TEXT, reason TEXT (enum: 'returned' | 'invalid' | 'opted_out'), suppressed_at TIMESTAMPTZ, notes TEXT.[63]
Usage: Whenever a mail piece is definitively un-deliverable or a recipient opts out, their address can be added here. For example, if an event mail_returned is logged, the system can mark that recipient’s address as suppressed (reason = returned)[64]. Future audience imports will be checked against this table; if a match is found, that recipient can be automatically marked as suppressed/invalid in the new audience[65]. Users can also manually add entries (e.g. if a customer calls to opt out), and remove or export the suppression list. This ensures known bad addresses or those who shouldn’t be contacted are excluded from campaigns, saving costs and respecting preferences.
      * leads – (Optional) Captures structured lead form submissions from the PURL landing pages.
Columns: id UUID PK, campaign_id UUID FK → campaigns, recipient_id UUID FK → recipients, full_name TEXT, email TEXT, phone TEXT, message TEXT, appointment_requested BOOL, submitted_at TIMESTAMPTZ.[66]
Usage: This table provides an easy reference of leads generated (conversions). When a recipient fills out the form on the landing page (which might ask for their contact info and interest), an event form_submitted is always recorded. Optionally, that data can also be inserted here for reporting or follow-up outside the event log[61][67]. This can simplify querying “how many leads did we get” or allow the sales team to export lead details. It’s considered optional because the event log itself holds the data; some implementations may skip the separate leads table and just rely on events.
Marketplace & Segmentation Tables: Supporting the lead purchasing and audience segmentation features.
         * lead_sources – Configuration of external lead data providers.
Columns: id UUID PK, vendor_name TEXT, api_endpoint TEXT, adapter_type TEXT, pricing_json JSONB, available_filters_json JSONB, active BOOL.[68]
Usage: Pre-configures marketplace data vendors. For MVP, ACE Engage might have a couple of dummy providers configured (or just one internal source). available_filters_json defines what filter options are offered (e.g. for Roofing leads: home age range, etc.), and pricing_json could define cost per lead or volume discounts. In the current phase, these are mostly placeholders since the marketplace uses a mock generator.
         * lead_filters_presets – Preset filter combinations for different verticals.
Columns: id UUID PK, vertical TEXT (e.g. 'roofing', 'rei', 'auto'), preset_name TEXT, filters_json JSONB.[68]
Usage: Stores saved filter sets that can be offered as one-click options in the UI (e.g. a “High-Value Roof Leads” preset that sets home age > 20 years and income > $100k). This makes it quicker for users to select common targeting scenarios. This table is auxiliary to the UI experience in the Marketplace.
         * lead_purchases – Records of lead list purchases/requests made through the marketplace.
Columns: id UUID PK, client_id UUID FK → clients, lead_source_id UUID FK → lead_sources, filter_json JSONB, quantity INT, price_cents INT, audience_id UUID FK → audiences, license_terms TEXT, purchased_at TIMESTAMPTZ, expires_at TIMESTAMPTZ, plus payment fields: stripe_payment_id TEXT, payment_status TEXT (enum: 'pending' | 'paid' | 'failed').[69][70]
Usage: Each time a user buys leads, a record is inserted here. It links to the resulting Audience (so the leads delivered are stored as a new audience) and stores what filters were used and how many leads. price_cents with quantity captures the cost (which could be used to invoice or charge via Stripe). license_terms might store any usage terms for the data (e.g. one-time use vs multiple mailings). The payment integration (Stripe) would fill stripe_payment_id and mark status as paid upon confirmation[71][70]. In the MVP, actual payment may be bypassed (marked paid by default or using a credits system), but the schema supports full integration when ready.
         * audience_segments – Stores segments derived from an audience via filtering rules.
Columns: id UUID PK, audience_id UUID FK → audiences, name TEXT, filter_rules_json JSONB, recipient_count INT.[72]
Usage: If a user creates a subset of an existing audience (for example, “California addresses” segment of a national list), it’s saved here. The filter_rules_json captures the conditions (similar to a WHERE clause on the recipients, e.g. state == "CA" AND validation_status == "valid")[73], and recipient_count is how many recipients matched. Segments can be used to run targeted campaigns or for A/B testing. For instance, one segment could receive variant A of a mailer and the rest variant B (the A/B test logic would create two campaigns or a campaign with variants)[74]. This table allows persistent reuse of complex filters and speeds up repeated queries by storing results.
Integration & Audit Tables:
            * webhooks – Registered webhook endpoints for event notifications.
Columns: id UUID PK, client_id UUID FK → clients, url TEXT, events TEXT[] (array of event types subscribed), secret TEXT, active BOOL, created_at TIMESTAMPTZ.[75][76]
Usage: Each row is a subscription for a client integration. For example, a client might register a webhook with URL https://example.com/ace_events and subscribe to events like mail.recipient.delivered and dm.form_submitted. The secret is used to sign event payloads (for security). Only active webhooks are invoked. Managing this table via the API or UI allows users to turn integrations on/off easily.
            * webhook_deliveries – Logs of webhook delivery attempts.
Columns: id UUID PK, webhook_id UUID FK → webhooks, event_type TEXT, payload_json JSONB, status TEXT (enum: 'pending' | 'delivered' | 'failed'), attempts INT, delivered_at TIMESTAMPTZ,error_message TEXT`.[75][77]
Usage: Whenever an event occurs, the system enqueues deliveries to each subscribing webhook. Each attempt (and result) is recorded here for debugging and auditing. If a webhook fails, it can be retried (the system is set to retry up to 3 times with backoff)[34]. This log can be surfaced in the UI (Integration settings) so developers can see if their endpoint is receiving and acknowledge events properly.
            * audit_logs – Audit trail of sensitive user actions.
Columns: id UUID PK, user_id UUID FK → profiles, client_id UUID FK → clients, action TEXT (e.g. 'export' | 'delete' | 'purchase' | 'view_pii'), resource_type TEXT, resource_id UUID, ip_address TEXT, user_agent TEXT, occurred_at TIMESTAMPTZ, details_json JSONB.[78]
Usage: Captures who did what and when, for compliance. For example, if a user exports an audience list to CSV, an entry with action 'export', resource_type 'audience', resource_id = that audience’s ID is logged (with timestamp and user info). Viewing PII (Personally Identifiable Information) or modifying key settings would also be logged[39][79]. These logs can be filtered and exported when needed (for security reviews or audits). The platform’s policy is to log all high-sensitivity operations to this table.
Note: Every main table includes created_at (and often updated_at). Many tables also have deleted_at for soft deletion (meaning the record is considered deleted when that timestamp is set, and excluded from normal queries via RLS or filters)[40]. Periodic jobs or cron-based edge functions may permanently purge or archive truly old data beyond retention limits (e.g. delete events older than 2 years, anonymize recipients after a certain period)[8][80]. This ensures the database remains performant and compliant with data privacy policies over time.
4. API Endpoint Structures (REST & Webhooks)
ACE Engage exposes a comprehensive RESTful API for integration, as well as a webhook system for pushing real-time events to client servers. All API endpoints are versioned under /v1/ and require authentication. For server-to-server API calls, an API key is used (passed in an HTTP Authorization header); for user-specific actions in the web app, the user’s session token is used – but the underlying endpoints enforce the same role-based permissions.
Below is an overview of key API endpoints by category, along with example usage:
Audience Management API: Allows external systems to import and manage mailing lists.
               * POST /v1/audiences/import – Import a new audience from file. Clients can upload a CSV (or XLSX) file of contacts. The API expects a multipart form upload with the file and returns a JSON response containing the new audience_id and summary of the import (total rows, how many valid, invalid, duplicates removed, etc.)[81][82]. This triggers the same server-side process as the UI import: streaming parse of the file, basic validation of required fields, and batch insertion into the recipients table. Example Response: { "audience_id": "<uuid>", "total_count": 5000, "valid_count": 4800, "invalid_count": 200, "errors": [ {"row": 123, "error": "Missing address"} ] }.
               * GET /v1/audiences – List audiences. Returns a paginated list of all audience records the API key has access to (i.e. the client’s own audiences). Supports query filters like ?source=import or ?page=2&limit=50 to navigate[83]. Each entry in the list includes audience metadata and counts.
               * GET /v1/audiences/{id} – Retrieve audience details. Returns full info on one audience, including summary stats (counts, status) and possibly a sample of recipients or a link to download the full list. (For security, the actual PII of recipients might be retrievable via a separate call or file download rather than raw JSON, depending on design).
               * DELETE /v1/audiences/{id} – Delete an audience. Marks the audience (and its recipients) as deleted (soft delete)[84]. After deletion, those recipients should no longer be available for new campaigns. The API will typically respond with a success status or the deleted resource ID.
               * POST /v1/recipients – Batch add/update recipients. Allows adding recipients to an existing audience via JSON payload[85]. The payload would include audience_id and an array of recipient objects (with fields like name and address). The server will upsert these into the recipients table (allowing updates if matching on some unique key like email or an external ID, if applicable). This is useful for integrating external CRMs: they can push contacts into an audience programmatically.
(Note: Additional endpoints could include exporting audience data, but in many cases that might be handled via a UI download or an asynchronous job due to size.)
Campaign Management API: Enables creating and managing campaigns via API (for systems that want to trigger mailings programmatically).
               * POST /v1/campaigns – Create a campaign. Accepts a JSON body with campaign parameters (name, template_id, audience_id, size, postage, mail_date, lp_mode, base_lp_url, utm_config, etc.)[86][87]. On success, returns a { "campaign_id": ..., "status": "draft" }. The campaign will be created in Draft status. This endpoint allows an external system to initiate a direct mail campaign in ACE without using the web UI.
               * GET /v1/campaigns – List campaigns. Returns campaigns accessible to the API key, with optional filtering by status (?status=mailed) or pagination[88]. Useful to sync or display status in another dashboard.
               * GET /v1/campaigns/{id} – Get campaign details. Returns all campaign info (similar to what the UI shows in a campaign detail page), possibly including aggregated stats or links to analytics.
               * PUT /v1/campaigns/{id} – Update a campaign. Allows editing a campaign’s details (only while it is in Draft). For example, change the mail_date or template before approval. If a campaign is already approved or sent, the API should reject edits (or allow only certain fields like name/UTM for record-keeping)[89].
               * POST /v1/campaigns/{id}/proof – Generate a proof. This would initiate generation of proof assets for the campaign (like a proof PDF or sample images). The response might include a URL to a proof PDF or a set of sample PURLs/QR codes. In the current design, proof generation (merging template with sample data) might be automatic when moving to “Proofed” status, but this endpoint allows explicitly triggering it via API[90].
               * POST /v1/campaigns/{id}/submit – Submit campaign to print. This triggers the print vendor submission workflow for an approved campaign[91]. The server will verify the campaign is approved and then create print_batch(es) and mark the campaign as in_production (or mailed, depending on sync). Response could contain the batch_id(s) or an acknowledgement. This allows automation – e.g. an external system could auto-approve proofs and call this to send out the mail.
               * GET /v1/print-batches/{id} – Get batch status. Returns the current status and details of a given print batch[92]. If the print vendor provides tracking (like when a batch was mailed or delivered), that info would be included. This helps an external system poll for updates if webhooks are not used.
Potential future endpoints (for completeness, though not explicitly listed in the prompt) could include Template management (CRUD for templates), retrieving events or analytics data via API, and managing suppression lists. Those can be added as needed, and an OpenAPI specification will enumerate all.
Authentication & API Keys: The REST API requires an API key for external use. Each client has a unique API key (ace_live_xxxxxx format) which is generated on client creation and stored hashed in the database[41]. The key must be included in requests as an Authorization: Bearer <key> header. The platform will validate this on each call and respond with HTTP 401 for invalid keys[30]. Note that this API key is scoped to that client’s data only; it inherits all the permission restrictions of a “client_user” for that client. Higher-level Org access via API could be provided by using an internal API key or an OAuth system in the future, but currently the API is primarily client-scoped.
Webhook Notifications: In addition to polling via API, ACE Engage can deliver webhooks to notify external systems of events in real-time. Webhooks must be configured (via UI or API) by providing a URL and selecting which events to subscribe to[33]. Once set up, whenever those events occur, ACE will send an HTTP POST to the URL with a JSON payload describing the event.
               * Event Types: Some examples of event types that can trigger webhooks include:
               * mail.batch_status.changed – A print batch’s status changed (e.g. from printing to mailed)[33].
               * mail.recipient.delivered – A mail piece was confirmed delivered to the recipient (via USPS scan)[33].
               * dm.qr_scanned – A recipient scanned the QR code on their mail (first visit with mobile UA)[33].
               * dm.purl_viewed – A recipient opened their PURL in a browser[93].
               * dm.form_submitted – A recipient submitted the form on the landing page[93].
               * dm.conversion.recorded – A generic conversion event (e.g. an appointment booked, or other offline conversion if tracked)[33].
               * Payload & Security: The webhook POST payload is typically a JSON object containing details like event_type, campaign_id, recipient_id (if applicable), and a timestamp, along with any relevant data (for form submissions, the form fields might appear, whereas for delivered events, maybe a delivery timestamp or carrier route). An example payload for a delivered event might be:

                  * {
  "event_type": "mail.recipient.delivered",
  "campaign_id": "123e4567-e89b-12d3-a456-426614174000",
  "recipient_id": "423e4567-e89b-12d3-a456-556614174000",
  "occurred_at": "2025-11-26T15:30:00Z",
  "data": {"address": "123 Main St, Springfield, IL 62704"}
}
                  * Each webhook delivery includes an X-ACE-Signature header (HMAC-SHA256 with the webhook’s secret key) so the receiver can verify the authenticity of the request[34]. The platform will retry the delivery a few times if it receives non-2xx responses, marking the status in webhook_deliveries log accordingly.
                     * Use Cases: A nonprofit’s CRM could use webhooks to automatically update a donor’s profile when their direct mail piece was delivered or when they responded via the PURL. An e-commerce platform might trigger an email or call center follow-up as soon as a mail piece is scanned by the recipient (indicating immediate interest). Webhooks make ACE an interactive part of a multi-channel ecosystem rather than a black-box mail sender.
The API and webhook systems are documented in the platform’s Developer Portal. The Developer Portal provides an OpenAPI (Swagger) documentation that lists all endpoints, their request/response schemas, and examples[94]. It also includes guides on obtaining API keys, setting up webhooks, and code samples in common languages[31][95] for quick adoption. This ensures that developers can integrate ACE Engage into existing workflows confidently and consistently.
5. Authentication and Role-Based Access Control
User Authentication: ACE Engage uses an email/password authentication system (with email verification) for interactive users. Upon signup, a new user record is created in the auth system and a corresponding profiles entry is generated via trigger[44][45]. Users can also be invited by Org Admins (for agencies or clients) to join the platform – invited users receive an email to finish setting up their account. Passwords are never stored in plaintext; they are managed by the authentication provider (which could be a service like Supabase Auth or a custom auth microservice under the hood). The platform may also support SSO in the future for enterprise clients, but core MVP uses standard email login.
Roles and Permissions: Every user is assigned one or more roles which determine their access level[47]:
                     * org_admin: Internal operations/admin – full access to all organizations, clients, and data in the system. This role is reserved for the ACE internal team or super-admins who manage settings and oversee campaigns across all clients.
                     * agency_admin: Partner agency users – can create and manage campaigns for any clients under their agency. They can typically add client accounts, manage client users, and view all data for their agency’s clients[3].
                     * client_user: Client users – can only access campaigns and data for their own company (client). They typically cannot see data from other clients or make high-level changes.
These roles are stored in the user_roles table and enforced through both backend policies and frontend logic. At login, the frontend might get the user’s roles (e.g. via a decoded JWT or an API call) to tailor the UI (e.g. hide admin sections from a client_user). However, authorization is primarily enforced server-side – the database RLS policies and API checks ensure that even if a malicious user manipulates the UI, they cannot access data outside their scope[48][96]. For example, the campaigns table has an RLS policy allowing SELECT only if the user’s ID matches the campaign’s client’s authorized users or the user has an org_admin role. Similar policies exist on audiences, recipients, etc., often using the has_role(uid, 'org_admin') helper or checking membership tables.
Role-Based UI and Navigation: The application’s interface adapts to the user’s role:
                     * An Org Admin sees all modules and typically an organization switcher (if managing multiple agency orgs)[3]. They have access to the Agency Management and Administration sections in settings, and can see all clients’ data. For instance, they might see a drop-down to impersonate or view each client’s campaigns.
                     * An Agency Admin sees modules for Campaigns, Audiences, Analytics, etc., but only for their own agency’s clients. They might have a client selection drop-down in the UI to switch between different client accounts they manage[97]. They also see an “Agency” section (for agency-level settings and possibly aggregated metrics across their clients) and can manage users for their clients.
                     * A Client User sees only their company’s data. They won’t see multi-client switching options or certain admin settings. The navigation might be simpler (no Agency section, no global Settings beyond maybe personal profile settings). They can create campaigns for their own company and view results, but cannot affect other clients.
For example, if a user is both an Agency Admin and also given a client_user role for a specific client (for testing purposes), the UI may allow toggling context (“Agency View” vs “Client View”) to see what a client would see. This is supported by the platform’s flexible role mapping (one user can have multiple roles). Generally, however, users will operate in one primary role.
Data Access Enforcement: The combination of user_roles and mapping tables (org_members, client_users) is used in queries and security policies to filter data. Some strategies implemented:
                     * Row Level Security (RLS): Enabled on all tables containing client data (profiles, user_roles, organizations, clients, campaigns, audiences, recipients, etc.)[98][99]. Policies reference either the auth.uid() (current user) or use the has_role() function. For example, for the profiles table: a user can SELECT/UPDATE their own profile (auth.uid() = id), and an Org Admin can select all profiles (has_role(auth.uid(), 'org_admin'))[100][48].
                     * No client-side role spoofing: Roles are never trusted from the client side alone (e.g. the app does not rely solely on a JWT’s role claim without server verification). They are not stored in browser localStorage etc. The server always verifies the user’s roles against the database on protected actions[101][102].
                     * Scoped queries: Many backend functions take the current user’s context into account. For instance, an API call to list campaigns will internally filter by client_id that the user has access to (derived from their roles/memberships). If a user tries to query an ID not belonging to them, it will come back empty by design of the RLS or explicit checks.
User Provisioning & Management: Org Admins can invite or create users and assign them roles (for their organization or clients). If an agency signs up a new client, they would create a client record and then invite that client’s users (assigning them the client_user role and linking to that client). The platform might automate some of this: e.g., if a client signs up via a self-service flow, it could create a new client entry and make that user a client_user for it.
API Key vs User Auth: It’s worth noting the difference between user authentication (above) and API keys for integration. API keys are associated with clients, not individual users, and are used for server-to-server integration. They effectively carry the permissions of the client (so they are like a service account for that client). A client’s API key cannot access other clients’ data, and the system treats those requests as client-level scope (there’s no concept of multiple roles with an API key – it’s tied to one client and acts with client_user privileges for that client). This separation allows revoking or rotating API keys without affecting interactive user logins.
Session Management & Security: Users login via a secure form; on success, a JSON Web Token (JWT) or session cookie is issued. All API calls from the frontend include this token for authentication. The platform likely uses short-lived tokens with refresh flows to enhance security. Standard practices like password hashing, rate-limiting login attempts, and multi-factor authentication (if enabled in the future) are or will be in place. On the database, sensitive personal data (PII) is protected – for example, fields like recipient addresses are only accessible to authorized users and could be encrypted at rest or masked in certain contexts (not explicitly in the current design, but something to consider as a best practice).
In summary, ACE Engage’s authentication and RBAC are designed to ensure each user sees only what they should, aligning with the multi-tenant nature of the system. This protects client confidentiality (agencies cannot see each other’s clients, clients cannot see others’ data, etc.) while allowing internal Org Admins full oversight. The combination of frontend role-based UI and backend row-level security provides defense in depth for authorization.
6. Campaign Lifecycle Logic
Direct mail campaigns in ACE Engage move through a defined lifecycle from creation to completion. This section outlines the stages and the system logic at each step, tying together the modules and data described earlier. Understanding this lifecycle is crucial for both using the system and developing features, as different components (data validation, user approvals, external calls, tracking) come into play along the way.
Stage 1: Audience Preparation (Import & Validation) – Before a campaign can be created, the user must have an audience (mailing list) ready. This can come from: a file import, manual entry, or the lead marketplace.
                     * Importing Leads: The user uploads a CSV or Excel file of contacts via the UI (Audiences module) or sends it via the API. The system processes the file in an edge function to handle large volumes efficiently (streams the file, rather than reading all into memory, allowing up to ~250k rows)[14]. It expects specific columns (at minimum: first_name, last_name, address1, city, state, zip)[82], with optional fields like email, phone, etc. As it reads, it performs basic validation: required fields present, ZIP code is five digits, etc. Duplicates can be detected (e.g. if the same name/address appears twice) and either merged or flagged; for MVP they are likely just flagged/removed with a count reported[103]. Each valid row becomes a recipient in the new Audience; invalid rows (missing data or obviously bad addresses) are either skipped or inserted with validation_status='invalid' and noted in an errors list. The result is an Audience record with counts of valid vs invalid addresses and possibly a preview of errors for the user to review[104]. (In early versions, address hygiene is basic – e.g., no full USPS address standardization or NCOA cleaning is done yet[105] – but those can be integrated later.)
                     * Manual Entry: For very small audiences or quick tests, users can manually input addresses via a form in the UI (e.g. “Add Recipients Manually” button)[106]. This allows adding a handful of contacts one by one. The system still creates an Audience and corresponding Recipient records, running the same validation on each field input (with inline feedback in the form). This is convenient for sending a test mailer to, say, 5 people without preparing a CSV file.
                     * Lead Purchase: Alternatively, the user might use the Marketplace to acquire a new list. In this case, after the filters and purchase are confirmed, the system generates the Audience behind the scenes and fills it with recipients (mock data in MVP). The audience’s source will be 'purchase' and it will already be marked as ready (since the data is presumed valid coming from the provider)[22]. A purchase could trigger an on-the-fly validation too, but generally it’s unnecessary for provider-supplied data.
                     * Validation Outcomes: In all cases, after creation, an Audience will have a status: ready if everything is good to go, or failed if something went wrong (e.g. file completely unparseable). It might also have status='processing' during the import if the user is watching progress in real-time[16]. The UI provides feedback such as “X valid addresses, Y invalid, Z duplicates removed” upon completion[107]. Users can download error reports or fix invalid entries (possibly editing right in the UI or re-importing a corrected file). Ensuring a clean audience upfront is critical because once a campaign is sent, any bad addresses mean wasted mail pieces and budget – something explicitly highlighted by stakeholders who noted tight budgets and the need to be efficient with who we send to.
Stage 2: Campaign Setup (Draft Creation) – With an audience prepared, the user creates a new Campaign (in Draft state). This involves:
                     * Entering Campaign Details: The user provides a campaign name and selects a mail template for the creative[108]. The template choice will determine the default size (e.g. 4x6 postcard vs letter) and layout. The user also picks which audience to send to (from a dropdown listing their ready audiences and showing counts)[109]. They choose the postage class (First Class for faster delivery vs Standard for cost savings)[110]. If scheduling is allowed, they select either “Mail ASAP” or a future send date (mail_date)[110].
                     * Landing Page & PURLs: Next, the user configures how the platform will handle recipient responses. They choose between Hosted Bridge Page or External Redirect for the PURL mode[54].
                     * If Redirect: they provide the base URL of their own landing page or site (e.g. https://www.clientwebsite.com/special-offer). The system will later append unique query parameters to track each recipient (UTM tags and a recipient id).
                     * If Bridge Page: they will use ACE’s built-in landing page. In this case, they might pick a theme or see a preview of the default page design[54], and will likely configure the form fields or CTA (call-to-action) text elsewhere (the default is a generic lead form).
                     * In both cases, UTM parameters are configured: the system suggests defaults (utm_source=directmail, utm_medium=postcard, and utm_campaign derived from the campaign name) which the user can override[56]. This ensures that if the PURLs redirect to the client’s site, their Google Analytics or other tracking will properly attribute visits to this direct mail campaign.
                     * Saving Draft: When the user completes the wizard (which may be multi-step), they hit save. At this point, a new campaign entry is created in the database with status draft[111], and the chosen audience, template, etc. attached. No mail has been sent yet; nothing has gone to a vendor at this stage. The campaign is essentially set up but not yet mailed or even fully finalized.
Stage 3: Proofing & Approval (Ready for Production) – Before sending a campaign to print, an approval step is required to ensure everything looks correct (this is especially important because mistakes in direct mail can be costly).
                     * PURL & QR Code Generation: If the campaign uses personalized URLs (which all campaigns in ACE Engage do by design), the system generates unique tokens and QR codes for each recipient. In the UI, once a campaign draft is created, the user (or the system automatically) triggers the “Generate PURLs/QR Codes” action[112]. This executes an edge function (e.g. generate-recipient-tokens) which:
                     * Iterates over all recipients in the selected audience and creates a unique token for each (if not already assigned by import) using a URL-safe ID generator (like nanoid, encoded for brevity)[53].
                     * Constructs each recipient’s personalized URL (PURL) following a standard format: e.g. https://engage.yourdomain.com/c/{campaign_id}/{token}[113]. (The actual domain and path can be configured, but /c/ stands for campaign redirect).
                     * Generates a QR code image that encodes that PURL (including the UTM parameters)[114]. A library is used to create a PNG or SVG. The image is stored in a cloud storage bucket, organized by campaign and recipient ID (e.g. qr-codes/{campaign_id}/{recipient_id}.png)[114].
                     * Marks each recipient record with their new token (updating the recipients.token field).
                     * The function processes in batches for efficiency, and returns a count of codes generated. The campaign status is updated from Draft to “proofed” when complete[115].
                     * In the UI, a progress indicator may show (“Generating codes for X recipients…”)[116], and upon completion, the user can see a few sample QR codes and PURLs for review[117] to verify they scan correctly.
                     * Proof Document: In parallel or after PURLs are ready, the user typically needs to review a proof of the mail piece. ACE Engage might generate a PDF proof that shows the postcard/letter with example data merged (like the first recipient’s name/address in place)[118]. This proof could be generated by combining the template design with sample recipient data (maybe via an HTML-to-PDF or a template rendering engine). The user can view this proof in the app (or download it). Ensuring the QR code prints clearly, the address is in the correct area, and any required legal text is present are critical points to verify.
                     * Compliance Checklist: The platform assists the proof review by providing a checklist of common direct mail compliance items (especially if the vertical or postal regulations demand certain content)[119]. For example:
                     * “Return address present” – If not, the user should add one to avoid mail being undeliverable.
                     * “Proper postage indicia” – e.g. an indicia or stamp area is part of the design.
                     * “Required disclaimers included” – Some industries (like finance or insurance) require specific wording.
                     * “QR codes scannable” – Ensure sizing/contrast of codes are okay. These are shown as a to-do list in the proof UI[119]. It’s up to the user to manually check them off mentally; the system doesn’t auto-verify design content beyond perhaps ensuring the QR code was generated.
                     * Approval: Once satisfied, the user clicks “Approve for Production”[120]. At this moment:
                     * The campaign’s status changes from Proofed to “approved”[121].
                     * The campaign is effectively locked – no further edits to audience, template, or settings are allowed (the UI should disable editing when a campaign is approved)[122].
                     * This step might record who approved and when (could be stored in the campaign record or an audit log).
                     * Now the campaign awaits submission to a vendor. The UI will now show a “Submit to Print Vendor” button, which was disabled or hidden before approval[123].
(In some organizations, an approval might involve multiple stakeholders or even an external client sign-off. The platform currently assumes a single-step approval by the user creating the campaign or their supervisor. If needed, additional workflow (like sending proof via email to a client for sign-off) could be layered on, but in MVP the user of the system does the approval directly in-app.)
Stage 4: Print Submission & Production – After approval, the campaign is ready to be sent out through an integrated print/mail vendor.
                     * Vendor Selection: The campaign record already has a vendor field chosen (for MVP, it might be defaulted or chosen during campaign creation if multiple are available). ACE Engage is built to integrate with vendors via API. In early phases, a Mock Print Vendor Integration is implemented[124], meaning the system simulates the submission without actually ordering prints. This allows end-to-end testing.
                     * Submit to Vendor: When the user triggers Submit to Print (or calls the API endpoint for it), the system calls an edge function (e.g. submit-to-vendor) with the campaign ID[125]. The function will:
                     * Double-check the campaign is indeed approved (to avoid sending drafts by mistake)[126].
                     * Create one or more print_batch records for this campaign. If the audience size is within the vendor’s single batch limit, one batch is made; if not, it splits into multiple batches (the chat design suggests splitting into max 10k per batch)[127]. Each batch is marked pending or printing initially.
                     * Communicate with the vendor’s API. In the mock scenario, this might just be a console.log or a no-op that returns a placeholder success. In a real integration, it would send the campaign data and maybe a PDF or template ID and list of addresses to the vendor. The vendor might respond with a job ID or estimated delivery date.
                     * For MVP, the function generates a fake PDF URL (for example, a link to a placeholder “your PDF is being generated” or a dummy file)[128]. In reality, the vendor would handle the actual mail piece PDF (especially if the vendor has their own templates).
                     * Update the campaign status to “in_production”[128] (production meaning it’s with the printer now).
                     * Return a response to the UI/API that includes perhaps the created batch_id(s) and any relevant info like an estimated mail date or vendor tracking ID[129].
                     * Post-Submission: The UI will reflect that the campaign is now in production. The user might see a status badge or timeline. They can click “View Batches” to see each batch and its current status[130]. Initially, statuses will be Printing (or similar). If using the mock flow, these statuses might be simulated over time for demonstration.
                     * Vendor Integration Considerations: In production, once integrated with a real vendor (like Lob or others), ACE Engage would send the actual content and addresses to that vendor. The vendor typically handles printing and injection into the postal system. The vendor might provide webhooks or APIs to update ACE when the mail is sent or if there are errors (e.g. address issues). In absence of that, ACE might update a batch to mailed on a scheduled mail_date or simply assume mailed after a short time for simulation.
Stage 5: Delivery Tracking – As mail is produced and enters the postal stream, ACE Engage tracks its journey (this is a key differentiator from just “sending mail” – tracking adds accountability and insight).
                     * Intelligent Mail Barcode (IMb): Each mail piece often carries a unique barcode that USPS scans at various points. If the print vendor provides access to those scans (via daily files or APIs), ACE can ingest them. In the MVP, this is simulated. A developer testing a campaign can hit “Simulate Mail Tracking”[29] which calls a function simulate-mail-tracking. This function:
                     * Takes a campaign and randomly marks ~80% of its recipients as delivered over a span of a few days (simulating normal delivery)[131].
                     * It generates events: for each recipient, perhaps an imb_in_transit and later an imb_delivered. It may also generate some mail_returned events (~3% to simulate bad addresses)[132].
                     * It updates recipient records with a delivery status if maintained (e.g. one could add a field on recipients for delivery_status or just infer from events)[133].
                     * It creates entries in the events table for these mail tracking events (with source='usps'). For example, if recipient John Doe’s postcard got delivered, an event with type imb_delivered and John’s recipient_id is logged at the simulated time.
                     * This simulation allows the UI to display a delivery timeline chart (cumulative or daily delivered mail count)[29] and to list recipients and their last known status. In a real scenario, similar events would come from parsing USPS data.
                     * Recipient Status: The campaign detail page now can show how many pieces have been delivered, how many are still in transit, and who they are. A recipient-level tracking table lists each contact with columns like Name, Address, and Status (Delivered/In Transit/Returned) and the date of last event[29]. This provides customer support info (e.g. if a client asks “did my VIP donor get the mail?”, you can check).
                     * Handling Returns: When mail_returned events are recorded (meaning a mail was undeliverable and came back), the system triggers suppression logic: those addresses get added to suppressed_addresses and that recipient’s validation_status may be updated to 'suppressed'[64]. This prevents future campaigns from retrying that bad address automatically, saving cost.
Once a campaign’s mail has all (or mostly) been delivered (or a certain time window after mail_date has passed), the campaign status could be updated to “mailed” or “completed”. In our schema, we had status='mailed' separate from 'completed'. We can define: - mailed: all batches have been sent out (mail is in the postal system or delivered). - completed: the campaign is functionally over – mail delivered and response window mostly passed. Perhaps an Org Admin or the system marks it completed when it’s no longer active.
Stage 6: Response Tracking & Attribution – As recipients respond to the mail by visiting their personalized URL or redeeming the offer, ACE Engage tracks these interactions to attribute offline mail to online/offline actions.
                     * PURL Visits: Each mail piece includes a Personalized URL (and QR code). When a recipient visits their PURL, the ACE Engage public-facing route /c/{campaignId}/{token} is triggered. This is handled by a special Edge Function or server route (handle-purl)[134]:
                     * It looks up which recipient corresponds to that {campaignId, token} combination. If found, it logs an event purl_viewed with the time, the recipient and campaign IDs[135].
                     * If the campaign’s lp_mode is "redirect", the function will 302-redirect the user to the base_lp_url associated with the campaign, appending the UTM parameters and possibly a unique rid (recipient id) parameter[136]. Example: redirect to https://clientsite.com/offer?utm_source=directmail&utm_medium=postcard&utm_campaign=spring-promo&rid=rec_xyz. This allows the client’s site to record the visit and even call back to ACE via API if needed.
                     * If lp_mode is "bridge", the function will instead serve a hosted landing page – i.e., it returns an HTML page (likely rendered by the frontend app) personalized for the recipient[137]. Before serving, it may set a cookie or otherwise mark the visit for session tracking.
                     * In both modes, the system captures context: the HTTP referrer (should be empty or direct in most cases), user agent, and IP address. Using these, ACE tries to infer if the visit came from scanning the QR code or not:
                     * If the user agent is from a mobile device and it’s the first hit for that token, and there’s no referrer, it likely means QR Scanned. The system may log a separate qr_scanned event in that case (or mark a flag)[138]. Essentially, every PURL visit event is examined: ACE can tag it as QR-driven vs manually entered. This is valuable because QR scans often indicate the user literally scanned the physical mail, whereas a direct visit could mean they typed the URL or clicked an SMS/Email that someone sent them the link (less likely).
                     * IP address can be geocoded (not in MVP, but planned via geocode_json field on recipient or event) to get city/state for reporting where responses come from.
                     * Bridge Landing Page: If using the built-in bridge page, what does it contain? It’s typically a simple web page branded to the client (logo and colors from the client settings)[139]. It might say, "Hello <First Name>," as a personalized greeting[140], then present an offer or message, some bullet points or images about the offer, and a lead capture form (see next) and a call-to-action button. The page could also include trackable links like a phone number (tel: link that triggers a call_clicked event when used) or an email link (mailto: triggering email_clicked event)[141]. The idea is to facilitate the conversion that the mail piece intended – e.g., sign up for a demo, schedule an appointment, claim a voucher, etc., and to track those actions.
                     * Lead Form Submission: For bridge pages, an embedded form lets the user respond. When submitted, an edge function submit-lead-form handles it[61]:
                     * It takes the form data (e.g. name, email, phone, message, plus maybe custom fields like “Interest level” or a checkbox for appointment request)[61].
                     * It validates that the recipient and campaign IDs are valid and correlated (to avoid any tampering)[142].
                     * It inserts a new event form_submitted with the data captured in event_data_json[143].
                     * Optionally, it can also insert into the leads table for easy reference[144].
                     * It might trigger a notification email to the client (for example, send an email to the sales team: "You got a new lead from Campaign X").
                     * It returns a success message which the page uses to show a “Thank you” confirmation (the UI might replace the form with a thank-you message or instructions for next steps).
                     * If the form had an “appointment requested” checkbox and the client uses Calendly or similar, the page could also load the scheduling widget after submission[145], but that is auxiliary.
                     * Phone Call or Other Conversions: Some mail campaigns aim to get recipients to call a phone number. If the number is unique per campaign or trackable via call tracking software, that could be integrated as well. For instance, if a call tracking system is used, ACE could treat a call as a conversion event (though this might be outside MVP scope). The screenshot and design hint at “Active Calls” and call tracking integration, but since the prompt is direct mail-focused, we consider those as possible future expansions. If integrated, events like call_received could be logged in events too.
Stage 7: Analytics & Follow-Up – As data on deliveries and responses accumulates, the platform provides analytics (covered in the next section) to evaluate performance. At this stage, the campaign is effectively completed, but the insights gained will inform future campaigns:
                     * Users can compare metrics like response rate (how many of the mailed recipients responded via PURL or other channels) against industry benchmarks.
                     * The platform can highlight ROI if cost data is entered (e.g. cost per lead, cost per response).
                     * If A/B tests were run (via segments or variant campaigns), results can be compared side by side to choose winning designs or lists.
Finally, users might choose to export data (e.g. export a list of responders or all recipients and their statuses) for external analysis or re-targeting. Such exports are logged in audit_logs for compliance[146].
Throughout this lifecycle, data validation and checks are built-in at each step: address validation on import, proofing checks before approval, status checks before vendor submission, and event-driven suppression to continuously clean the data. These ensure that campaigns maintain high data quality and compliance, crucial for achieving the strong ROI mentioned (stakeholders noted many clients expect a 5:1 return, which is only feasible with good targeting and follow-through).
7. QR Code & PURL Handling Logic
Personalized URLs (PURLs) and QR codes are central to ACE Engage’s ability to connect physical mail with digital actions. The platform automates the generation and tracking of these to provide per-recipient attribution. Here we detail how PURLs and QR codes are created, delivered, and tracked:
Token Generation: Each recipient in an audience gets assigned a unique identifier (token) that will be part of their PURL. During audience import, a token may be generated if not provided. More typically, upon campaign proofing, the system generates tokens for all recipients of that campaign audience[53]. Tokens are designed to be relatively short but unique; for example, using a Base58 or Base36 encoded random string (nanoid) of ~6-10 characters yields millions of possibilities and avoids ambiguous characters[113]. This token is stored in the recipients.token field and indexed for quick lookup when a PURL is hit[7].
PURL Format: The platform’s default PURL format is:

https://{trackingDomain}/c/{campaignId}/{token}
where {trackingDomain} is a domain or subdomain set up for ACE Engage’s tracking (could be a generic domain or custom for each client), {campaignId} is the campaign’s UUID (or a shorter hash of it), and {token} is the per-recipient token. Example: https://engage.acemail.com/c/8f3d9a7e/Ab12XY
This structure ensures that with just the URL, the system knows which campaign and which recipient (via token) it is, without revealing the person’s actual name or address in the URL (privacy conscious). The inclusion of campaignId in the path helps route to the correct campaign context quickly (one could also design it to look up token globally, but scoping by campaign can be convenient and adds a layer of uniqueness).
QR Code Generation: For each PURL, the system generates a corresponding QR code image so that users can just scan the mail piece instead of typing a URL. During the PURL generation process, ACE uses a QR library to encode the full URL (including UTM query parameters) into a QR code graphic (PNG format by default)[114]. The QR is typically a square image; the system can generate it at an adequate resolution for printing (e.g. 300 DPI, sizing maybe 1 inch square on the mail). The images are stored in cloud storage, and a reference could be stored or dynamically generated when creating the print file. In the print template, a placeholder or merge field indicates where the QR should be placed; at print time, each piece gets its unique QR from storage.
Placing on Mailer: The template design accounts for a QR code area. ACE might not actually merge the QR into a single PDF file for all recipients (that could be huge for large campaigns). Instead, the vendor might handle merging, or ACE could generate a PDF per recipient on the fly (not ideal at scale). More likely, ACE provides the vendor with a template and a CSV of URLs/tokens, and the vendor does the rest. For our logic, assume the QR is effectively on the mailer addressed to that recipient.
Landing Page Mode – Redirect vs Bridge: As mentioned, campaigns can either drive recipients to an external page or to a hosted page:
                     * Redirect Mode: The PURL will ultimately send the user to the client’s website. For example, the mail might say “Visit acme.com/offer” which is actually a PURL that goes to ACE first and then redirects. ACE append the query parameters (UTM, and possibly a unique ID). So if John Doe’s token is Ab12XY, his postcard’s QR might encode https://engage.acemail.com/c/8f3d9a7e/Ab12XY. When he scans it, ACE logs purl_viewed and then 302 redirects him to https://acme.com/offer?utm_source=directmail&utm_medium=postcard&utm_campaign=springpromo&rid=Ab12XY (for instance). On Acme’s site, their analytics sees those UTM tags, and the rid can be used if Acme’s site wants to call back to ACE (for example, to pull more info or send an event back confirming conversion).
The logic in handle-purl function checks lp_mode: if 'redirect', perform the redirect with proper encoding of parameters[137]. It ensures no HTML content is shown (just a quick redirect). One subtlety: if multiple calls come for the same token (e.g. user refreshes, or shares link), each will log a view event – ACE might de-dupe or at least record that first vs repeat visits if needed.
                     * Bridge Mode: The PURL will show a page served by ACE. In this case, handle-purl will gather the data needed (campaign info, maybe client branding, and recipient first name for personalization) and then serve an HTML page (the "bridge page")[147]. This page is likely a React page in the frontend app, but since the user is hitting ACE’s domain, ACE can decide to either:
                     * Render a server-side template (e.g. using a templating engine to inject name, etc.), or
                     * More simply, serve a minimal HTML/JS that bootstraps the React app in a special "public mode" for the landing page. The React app could then call an API like /v1/campaigns/{id}/recipient/{token} to fetch details (which would check the token and return needed info including maybe a one-time use auth or just the necessary content). Given complexity, the server-side approach might be straightforward for MVP: embed the needed data in the page.
The Bridge page contains elements described earlier: a personalized greeting, some marketing content (could even reuse the postcard’s imagery or theme), and crucially the Lead Capture Form. The form is dynamically tied to that campaign & recipient so the submission can be tracked.
                     * UTM Parameters: Even in bridge mode, ACE could still append UTM parameters when the user’s browser loads resources (though if staying on the same domain, it’s internal). If the client has analytics on their site, they might not see the UTM since user hasn’t gone to the client site yet. If the user clicks a link from the bridge page to the client site, then UTMs should be added to that link.
Event Logging: Every time a PURL or QR is used: - ACE logs a purl_viewed event when the page is accessed[135]. If the same person comes back later, it might log again or could be configured to only log the first unique visit per token (the design suggests capturing first-time vs repeat is useful). - If conditions suggest it’s via QR (first visit, mobile UA), an additional qr_scanned event is logged[148]. Alternatively, purl_viewed event could carry a flag in event_data like "via":"QR" for consolidation. The spec suggests separate events for clarity. - If on the bridge page the user interacts: clicking the phone link logs call_clicked, clicking an email link logs email_clicked[141] (these would be events with source 'form' or 'purl' but type indicating the action). - If they submit the form, a form_submitted event logs the details[143] (and optionally a lead record). - All these events link by recipient_id and campaign_id, providing a timeline of that recipient’s journey.
Usage of Tokens in Analytics: Because each response event is tied to a recipient via the token, ACE can calculate metrics like: what percentage of recipients scanned the QR or visited the page, and who they are. This is powerful for attribution – proving that out of, say, 5,000 mailers, 500 people visited their PURL (10% engagement), 50 filled out the form (1% conversion), etc., and even down to which 50 (so sales teams can follow up). In traditional direct mail, if a generic URL or phone is used, you can’t easily know which specific mail piece drove the response, but with PURLs you can.
Scalability considerations: The number of tokens generated equals number of recipients. The system should ensure tokens are unique at least per campaign. If a recipient is mailed multiple campaigns, they will have different tokens (one per campaign) to differentiate responses by campaign. The token generation is quick and lightweight compared to other tasks, but storing potentially millions of QR images could be heavy – to mitigate, ACE might generate them on-demand or use a dynamic QR generation service for each scan (but caching images is simpler for print). The storage path ensures easy cleanup if a campaign is deleted (e.g. remove that folder of QR codes).
Data Privacy: PURLs inherently encode a unique ID for a person, so ACE uses a non-guessable token to avoid any brute-force enumeration of recipients. Also, the token by itself doesn’t expose personal info without access to the database. If someone randomly finds a PURL, at most they’d see the landing page with perhaps first name – sensitive details like address are not shown on the page. All PURL traffic is over HTTPS to avoid sniffing. The system should also handle an edge case: if a PURL is hit for a campaign that’s not active or a token not found (maybe user error typing URL), the handler can redirect to a generic page or show an error ("This offer is no longer available", etc.), rather than exposing any system info.
In summary, ACE Engage’s PURL/QR system automates the bridging of physical and digital: every mail piece carries a call-to-action that is uniquely trackable. This yields rich data on engagement and ensures that the often expensive direct mail efforts can be measured and tied to outcomes, fulfilling the platform’s promise of analytics-driven direct mail.
8. Audience Marketplace & Segmentation Structure
This section covers two advanced features around audience data: the Lead Marketplace, where users can acquire new contacts, and Segmentation, where users can subdivide and test portions of their audiences.
8.1 Lead Marketplace (Buying Targeted Leads)
One challenge for direct mail campaigns is obtaining high-quality contact lists for prospects (especially if the client’s own database is limited). The Audience Marketplace addresses this by letting users purchase prospect lists filtered by various criteria, directly in the platform.
Marketplace UI Flow: The marketplace is accessed as a tab in the Audiences module (labeled "Marketplace" or "Buy Leads")[149][150]. The user is guided through a multi-step wizard:
                     1. Select Vertical: The user chooses the industry or campaign type, such as Roofing, Real Estate Investors (REI/Flippers), Automotive etc. This selection tailors the available filters to those most relevant for that vertical[18].
                     2. Choose Filters: For the chosen vertical, a set of filters is presented. These correspond to fields like demographic or property attributes. For example:
                     3. Roofing Leads: filters might include Home Age (e.g. homes older than 20 years, since older homes likely need roof replacement), Roof Age (if data available), Hail Risk Zone (geographic regions prone to hail damage), Homeowner’s Income Band, Credit Score Range etc.[19].
                     4. REI/Flipper Leads: filters might include Absentee Owner flag, Equity % (how much equity in the property, indicating potential to sell), Ownership Length, Property Distress Indicators.
                     5. Auto Leads: could include Vehicle Make/Model/Year, Mileage Band (to target owners likely needing service or trade-in), Last Service Date (to find those due for service), etc.[19]. These filters are presented as forms (dropdowns, sliders, checkboxes). The definitions of these filters and options come from the lead_sources.available_filters_json or preset logic.
                     6. Geographic Targeting: The user specifies where the leads should be located. MVP may keep this simple: perhaps a text box for ZIP codes or a radius from a city. Ideally, advanced tools like drawing a polygon on a map could be future improvements, but initially a list of ZIP codes or counties might suffice[151]. E.g., user could enter "Within 50 miles of 90210" or "ZIP codes: 90001, 90002, …".
                     7. Quantity Selection: The user sets how many leads they want to purchase. Often there’s a minimum and maximum (e.g. 500 to 50,000 leads)[152]. A slider or input is used to choose a quantity. This number along with pricing info will determine cost.
                     8. Pricing & Checkout: The system calculates an estimated price based on the quantity and perhaps filter premium (some filters might cost more). For example, a note might display “~$0.15/lead = $750 for 5,000 leads” as an estimate[153]. The user then proceeds to payment. In MVP, actual payment can be simplified or skipped; the design suggests integration with Stripe as an option, or using a credit system[154][155].
                     9. Confirmation: After purchase, the user sees a success message like “Your leads are ready! View Audience.”[156] The platform creates a new Audience containing the purchased leads.
Backend Process (purchase-leads function): When the user confirms buying leads (and presumably payment is authorized): - ACE calls an edge function purchase-leads with the selected filters and quantity[157]. - The function validates input and either simulates calling a lead provider API or directly generates leads. In MVP, no external API is actually called; instead: - It uses a library like Faker to generate fake but realistic data that meets the criteria[158]. E.g., if “home age > 20” was a filter, it might ensure the addresses generated have properties built before 2005. For “state = TX”, ensure addresses are in Texas, etc. This is complex but possible with a rich fake data set and some logic. - It creates a new Audience record, e.g. named “Lead Purchase Nov 26 – Roofing” with source='purchase'[22]. - Inserts the generated contacts as recipients under that audience (batched inserts like imports do). - Records a lead_purchases entry linking to the new audience, storing the filters, quantity, price, and marking as paid. - It returns back to the UI the new audience_id and maybe some summary (quantity delivered, cost)[159].
If Stripe integration is enabled: - The UI would redirect to a Stripe Checkout page at step 5 instead of immediately calling purchase-leads[24]. After payment, a Stripe webhook would notify ACE (to an endpoint like /webhook/stripe) and ACE would then internally call the same purchase-leads function to generate the audience[160]. This way, leads are only delivered after payment confirmation. - The lead_purchases.payment_status would start as 'pending', then get updated to 'paid' on successful webhook[70]. - In case of payment failure, it would be 'failed' and no audience generated (or audience remains empty/inactive).
Data Source & Future Integration: For MVP, lead data is fake. In the future, this feature would integrate with real data brokers like Melissa Data, Experian, etc. Those providers have APIs where you send filters and get back a batch of leads (usually with costs). The architecture already anticipates that: lead_sources table could hold API endpoints and adapter types (maybe different code to fetch from different vendors). When real integration happens, purchase-leads would call the vendor’s API, get real contact data, perhaps store the raw data or directly insert it. One must handle vendor-specific licensing (some data might only be used once unless repurchased, etc.).
Value Proposition: The marketplace makes ACE Engage a one-stop shop: not only can clients mail their existing contacts, they can easily find new prospects by criteria, removing friction (no need to go to a separate broker, export/import lists, etc.). It’s a revenue opportunity as well (ACE could mark up the data cost or get affiliate deals). Technically, it also ensures that once purchased, the leads flow right into an Audience ready to be used in a Campaign, simplifying the workflow.
8.2 Audience Segmentation & A/B Testing
Segmentation allows users to carve up an audience into targeted sub-groups. This can be used for focusing on a specific demographic or for A/B testing different mail strategies.
Segment Creation: On an Audience detail page (where the list of recipients is shown and summary stats), the user has the option to “Create Segment”[73]. This opens a segmentation builder interface: - The UI likely presents a rule builder, where the user can add one or multiple conditions (like building a query filter visually). For example: - Where city = "Dallas" AND state = "TX" (to get Texas/Dallas folks)[161]. - Where validation_status = "valid" (maybe to filter out invalids, though by default you’d use only valid anyway). - Potentially conditions on response metrics (if doing post-campaign segmentation, e.g., "where last_event = delivered"). - If we had any calculated engagement scores (not in MVP but possible future: e.g. an algorithm rates recipients by likelihood to respond), those could be filterable too[162]. - The rule builder might offer drop-downs for fields (any column in recipients or maybe also campaign events like “people who clicked the QR”). MVP likely sticks to recipients’ own fields.
After defining rules, the user gives the segment a name and saves. The system will: - Evaluate the rules against the recipients of that audience, count how many match. - Create an audience_segments row with the JSON representation of those rules and the count[72]. - Possibly tag each matching recipient or otherwise store the list of IDs (though not necessary since you can re-query when needed, but storing count is for convenience).
Using Segments: Once a segment exists, users might: - Launch a new campaign just to that segment. Instead of selecting a full audience, the UI could allow selecting a segment of an audience (the system would behind-the-scenes treat it as filtering recipients at send time). Alternatively, when a segment is chosen, the platform could spawn a new Audience that contains only those recipients (like a static sub-list). However, maintaining a dynamic link is more efficient (if one updates the original audience or adds recipients, the segment could update if re-run). - Compare performance: If a campaign was sent to a full list but had two segments defined, analytics could potentially break down results by segment. - For A/B testing: The UI might offer a simpler way: a toggle “Split audience for A/B test”[74]. If activated, ACE could automatically split the audience into two segments (e.g. randomly, 50/50). The user would then choose variant A template for segment 1 and variant B template for segment 2. Under the hood, this could create two campaigns (one per variant) or one campaign with an internal reference to two templates and a segment division. The chat prompt suggests treating them as variant A and B with separate tracking, and then providing a comparison dashboard (which would essentially just compare the two campaigns’ metrics)[74].
Given the complexity, MVP might skip deep integration of A/B in one campaign object and instead instruct users to do it manually: e.g. create two campaigns, each to a segment of the audience, with different templates. But since A/B testing was explicitly mentioned in designs, we note it: - A/B Testing Implementation (conceptual): If built-in, once “Split test” is toggled and two variants configured, the platform randomly assigns each recipient in the audience to either variant A or B (ensuring roughly equal splits). It then duplicates the campaign info: same audience, but Template field is different for B (or perhaps a different mail content variation) and likely appends “(Variant A)” and “(Variant B)” to campaign names internally. When tracking results, it can label events by variant. The analytics module could then show a side-by-side: e.g. Variant A QR scan rate vs Variant B, etc. This helps determine which design was more effective.
Technical Storage: The audience_segments.filter_rules_json would store something like:
{"conditions":[{"field":"city","op":"=","value":"Dallas"},{"field":"state","op":"=","value":"TX"}],"logic":"AND"} to represent City = Dallas AND State = TX.
To get the recipients, one would either dynamically query the recipients table with those conditions whenever needed (the count stored is to display segment size without querying every time). If segments need to be used like separate audiences, one could join or select from recipients where conditions match. If performance is a concern for large lists, one approach is to materialize the segment: e.g. create a new audience or list of recipient IDs belonging to it. MVP likely avoids that to reduce data duplication, relying on queries.
Use Cases for Segmentation: - Targeted Messaging: Suppose a charity has an audience of donors, they might segment by donation amount or location and send slightly different letters to high-value donors vs low-level donors (by creating two segments and two campaigns with tailored templates). - Testing Offers: A car dealership could send half the list a postcard offering a $500 trade-in bonus, and the other half a postcard offering 0% financing, to see which promo yields more responses. - Operational Segments: Perhaps to stagger mailings, an audience could be segmented by last name (A-M, N-Z) if they want two drop dates.
Marketplace & Segments Combined: One could purchase a broad list then segment it. For example, buy 10,000 automotive leads nationwide, then create segments by state and run region-specific campaigns. Or vice versa: one could segment first-party data to decide who to supplement with purchased leads.
In summary, Marketplace brings new data in, and Segmentation allows slicing data up. Both increase the precision and power of direct mail campaigns. The system architecture supports these by additional tables and logic (which we have in place in the schema with lead_* and audience_segments). As these features evolve, performance and data integrity will be important (especially if dynamic segments are used in queries, making sure indexes on recipient fields are in place to speed up filtering).
9. Attribution and Event Tracking
Attribution in ACE Engage refers to linking the outcomes (responses, conversions) back to the direct mail that caused them, as well as tracking the mail delivery itself. The platform implements an event-driven tracking system to capture all relevant happenings in the lifecycle of a mail campaign. We’ve touched on many events already; here we consolidate and detail how attribution and tracking works, particularly for mail events, QR/PURL interactions, and form submissions.
Event Model: All events are recorded in the events table, forming a timeline of actions per recipient[58]. Each event has: - event_type: describes what happened (delivery milestone, scan, view, submit, etc.). - campaign_id and recipient_id: context of who/what this event is tied to. - occurred_at: timestamp. - source: origin of the event data, e.g., 'usps' for mail events, 'qr' or 'purl' for digital interactions, 'form' for form submissions, 'external' for anything logged via API or other sources.
Using these events, ACE Engage can build a complete story for each recipient: e.g. Mailed -> In transit -> Delivered -> QR scanned -> PURL viewed -> Form submitted[163]. This helps in analyzing drop-off points (how many delivered but not scanned? scanned but not submitted? etc.)
Mail Tracking Events: If integrated with USPS Intelligent Mail (or through the print vendor), ACE collects a series of scans: - imb_injected: Mail piece was inducted into the postal system (handed off by the printer, or processed at origin facility). - imb_in_transit: A sorting facility scan, indicating it’s moving along. - imb_out_for_delivery: Put on a truck for final delivery. - imb_delivered: Marked as delivered to mailbox (this is often a scan by the carrier or a computed event after out-for-delivery in USPS Informed Visibility data)[59]. - mail_returned: The piece was returned as undeliverable (could come weeks later if at all)[164]. These events have source 'usps'. They may include in event_data_json fields like facility code, scan time (though we use occurred_at too), maybe a USPS status code. ACE uses them to update statuses: - The first in_transit could be used to count how many mails are on the way. - delivered events drive delivery rate metrics (e.g. Delivered count / Total mailed). - returned triggers suppression logic as described (and could decrement the delivered count for effective reach calculations).
Since we may not have live USPS data in MVP, the simulation generates these with random delays to mimic a realistic pattern[131]. For real data, a background job might poll the vendor or USPS daily and insert events accordingly.
QR Code Scans and PURL Views: As covered, when a PURL is accessed: - A purl_viewed event is always logged (with source 'purl'). We might include data like {"ua":"Mozilla/5.0 (iPhone)...","referrer": ""} in event_data. - The logic to differentiate a QR scan: if conditions match (mobile device and likely first time), log a qr_scanned event (source 'qr') either immediately before the redirect or as part of the handling logic[165]. This way, the system counts scans separately. Why separate? Because if someone saw the URL on the mail and manually typed it on their laptop, that’s a PURL view but not a QR scan. Knowing how many used the QR code vs typed can gauge the effectiveness of the QR placement or the vanity URL memorability. - These digital events allow calculation of Click-through Rate (CTR): e.g. QR Scans / Delivered as a percentage. If 1000 pieces delivered and 50 scans, that’s 5% engagement via QR. Also a PURL visit rate which might be slightly higher if some typed in (so includes QR_scanned + others). - The recipient_detail page (if implemented) or analytics can show each person’s progression: e.g. John Doe: Delivered on 11/20, QR scanned on 11/22, Form submitted on 11/22[163].
Form Submissions and Conversions: - The form_submitted event (source 'form') contains the payload of what was filled in[143]. This is PII and sensitive (name, email, etc.), but it's stored likely because the client will want that data and to measure conversion quality. ACE likely also copies this into the leads table for easy retrieval. - Additional conversion events: the design lists dm.conversion.recorded as a possible webhook type[166]. This suggests the platform might allow logging a custom conversion (maybe via API or manual input). For instance, if the ultimate goal is an appointment booked, which might happen outside ACE (say the client calls the lead and schedules an appointment), the client could use the API to send a conversion event linking to that recipient. This is speculation based on the event name, but it indicates the architecture foresees user-defined events as well. - Each form submit can be tied back to a mail piece, giving a true conversion attribution. If the client closes a deal worth $$, they can ultimately trace it to the mail ID – powerful for ROI calculations.
External Event Sources: There is 'external' source type reserved[167]. This could be used if, for example, we import phone call tracking events or other offline events. If the platform ingests data from another system (say call center logs or in-store redemption codes), those could be recorded as events with source 'external'. E.g., a record that someone came to the dealership and redeemed a coupon could be logged to events for completeness.
Real-Time Aspects: The presence of webhooks means whenever an event is inserted, the system immediately tries to notify subscribers[34]. For instance, a client’s system could get a webhook "dm.form_submitted" with the lead details in near real time, allowing their sales team to react quickly (minutes after a person submits interest, they get a follow-up call). This greatly improves the timeliness of direct mail response handling.
Metrics Derived from Events: (This flows into Analytics, but briefly) - Delivery Rate: = Delivered events / total recipients (e.g. 95% delivered, meaning 5% returned). - Response Rate: = form_submissions (or desired conversion events) / delivered, often expressed as a percentage[168][169]. In nonprofit fundraising, response rate might be donations made; in marketing, maybe leads captured. - Engagement Rate: can consider any PURL view or scan as a response as well (even if they didn't fill form). So one might track “Engagement” separate from “Conversion”. E.g. QR/PURL CTR = (unique PURL viewers) / delivered. - Timeline Metrics: The events have timestamps, so one can chart cumulative deliveries by day, and cumulative responses by day. Typically, direct mail responses skew in the first 1-2 weeks after delivery and then tail off. The system could highlight average time from delivery to response (this can be derived by comparing timestamp of delivered vs submitted events per recipient)[163].
Attribution across channels: If ACE is integrated with other channels (it currently focuses on mail), events can unify data. But even within mail, attribution sometimes extends to offline actions (like calls or in-person visits). Those might not be automatically captured unless mechanisms are in place (unique phone numbers, or asking people to bring the mail to an event, etc.). ACE primarily attributes digital traces to the mail via PURLs. If unique coupon codes were used, a future feature could allow input of redeemed codes as events.
Data Volume and Retention: Each mail piece could generate multiple events, so the events table might have, say, up to ~4-5 events per recipient (for those who go through the funnel) and at least 1-2 for everyone (injection, delivery, etc.). That could be hundreds of thousands of events for big campaigns. Proper indexing on (campaign_id, event_type, recipient_id) is important for querying. Over time, old events might be archived or deleted as per retention policy (e.g., drop events after 2 years[170]). Before deletion, aggregated metrics would be stored or remain in campaign stats.
User Interface for Events: - At campaign level: a timeline chart showing counts of delivered, scanned, form submits by date[27]. - At recipient level: maybe accessible via clicking a recipient to see an event timeline (like a mini log of that person’s events). - A list of events (like a feed of latest responses) could also be on the dashboard or campaign page (for instance, “Recent Activity: John Doe submitted form (Campaign X) on Jan 5th”). - The suppression list view pulls from events of type mail_returned to show what got auto-suppressed.
Accuracy and Validation: There can be scenarios where events might not line up perfectly: - A PURL might be visited by someone other than the intended recipient (if they forwarded the mail). The system can’t know that, it still logs under that recipient. - If a user scans QR multiple times, we will have multiple events. The analytics might count unique vs total scans accordingly (unique visitors vs total visits). - If a mail is delivered but the scan event missed (USPS data not 100%), then delivered count might be undercounted. Generally, USPS has high coverage though. - If no event at all comes for a recipient, one assumes not delivered (or at least not confirmed). The platform might treat all those as undelivered for conservative metrics.
Developer Note: Implementing this event pipeline involves setting up either polling jobs or webhooks for USPS data, capturing the redirect hits (likely trivial via the web framework), and making sure the form submission writes events. Also the logic for QR detection might rely on user agent strings which can be brittle (need to maintain a list of mobile UA substrings).
In conclusion, ACE Engage’s event tracking infrastructure is what enables closed-loop attribution – from a piece of mail sent to a sale or action taken. This level of detail is what sets it apart from traditional direct mail (where you’d often just measure response by manually counting returned business reply cards or coupon codes). Here, every interaction is tracked and can be analyzed, giving marketers and fundraisers the data to justify and optimize their direct mail spend.
10. Analytics and Metrics Display Logic
Analytics in ACE Engage turn raw event data into meaningful insights through an intuitive UI. The platform provides both high-level dashboards and detailed campaign-specific analytics to measure effectiveness of direct mail campaigns. We’ll describe the key metrics, charts, and logic behind the analytics module, as well as how data is presented for user decision-making.
Key Performance Indicators (KPIs): On a campaign analytics page (or dashboard), the following KPIs are typically highlighted[25]:
                     * Mailed / Sent: The total number of mail pieces sent in the campaign. This is essentially the audience count (minus any suppressed addresses). It provides the denominator for many rates. E.g., “5,000 Mailed” displayed.
                     * Delivered: How many mail pieces have been confirmed delivered (via events). This could be shown as an absolute number and/or a percentage of mailed (delivery rate). For example, “4,750 Delivered (95%)” if 250 were undeliverable.
                     * QR Scans: Number of unique QR code scans recorded. Also often expressed as a percentage of delivered (this is the initial engagement rate from physical to digital). E.g., “500 QR Scans (10.5% of delivered)”[171].
                     * PURL Views: Total unique PURL visits. In many cases this will be equal to QR Scans if most use QR, but if some manually visit or share the link, PURL views might be slightly higher. It can be shown similarly as count and maybe a % of delivered.
                     * Form Submissions (Leads): The count of forms submitted (leads captured). This is a direct measure of conversions from the campaign. It’s often expressed as a Conversion Rate relative to delivered or mailed – e.g., “50 Form Submissions (1.0% conversion)”[172].
                     * Appointments Booked / Sales (if applicable): If the campaign tracks further down-funnel actions (like an appointment or a purchase), those can be KPIs too. The prompt suggests vertical-specific KPIs: for roofing, perhaps “Inspection Appointments,” for auto, “Redemption Rate” etc., which implies if those are being captured they’d be shown[173]. These may not be MVP but the design is considering them.
                     * Cost Metrics: If cost info is available (say printing cost and postage, or lead purchase cost), Cost per Response or Cost per Lead can be calculated[174]. E.g., if $750 was spent on a campaign that yielded 50 leads, Cost per Lead = $15. This is highly valuable for ROI calculations.
                     * Return on Investment (ROI): Not explicitly in text, but if revenue or donation amounts are tracked externally and fed back, ROI could be shown. Possibly MVP doesn’t track monetary outcome directly, but integration with CRM could allow it.
These KPIs are often shown as cards or summary boxes at the top of the analytics page for quick reading. They might be color-coded (green up arrows for positive trends, etc.). For example, “Delivery Rate 95%” might have a green check icon, “Response Rate 1%” might be neutral or compared to a benchmark.
Trend Charts: Visualizing how the campaign performed over time is crucial: - Delivery Timeline: A line or area chart showing how the mail deliveries progressed each day since the mail drop[27]. For example, an area chart could have X-axis = days after mail date (Day 0, Day 1, ... Day 14) and Y-axis = number of recipients. We could plot: - Mailed (cumulative mailed, which jumps on the mail date). - Delivered (cumulative delivered, which might start a couple days after mail date and plateau once most delivered). - Responses (Forms) (cumulative submissions). - QR Scans (cumulative). This shows the lag between mail and response. Perhaps instead of cumulative, it could show daily count lines (like how many delivered each day vs how many responses each day). - The design mentions lines for Mailed, Delivered, Scanned, Forms on one chart[27]. Possibly using separate y-axes or normalized to percentage could help if scales differ widely. But likely they overlay counts. - This timeline helps answer: Did responses spike immediately after delivery? Is there a long tail?
Geographic Distribution: If addresses are geocoded or at least include state/ZIP, the platform can show where responses are coming from: - A map visualization shading states or areas by response rate or by number of leads[175]. E.g., Texas shows 10 responses, California 2, etc. For local campaigns, maybe a map of counties or ZIPs. - If a map is too complex in MVP, a simple table by State or City: State: TX – 50 responses (10%), CA – 30 responses (5%) etc.[175]. This identifies geographic pockets that perform well or poorly. - This can guide clients to focus future mail on certain areas. For instance, "we got a lot of scans from Florida, maybe we should double down there."
Recipient-Level Detail: A table listing each recipient and their outcomes[176]. Columns might include: - Name, City, etc. (basic info), - Delivered Date (if delivered), - QR Scan (yes/no or date if yes), - PURL Viewed (yes/no), - Form Submitted (yes/no or date), - Last Event (some might have 'Delivered', some 'Form Submitted' etc.). This table can be filtered (show me all who scanned but did not submit, for example)[177]. It can also be exported to CSV for sales follow-up or record-keeping[178]. For privacy, maybe not all info is shown to all roles (e.g., if sharing analytics externally you might hide names).
Comparative Analytics & Benchmarks: The mention of vertical-specific KPIs[173] suggests that for certain industries, we track specialized metrics. For example, in an automotive service campaign, maybe the metric of interest is how many service appointments were scheduled or how many coupons redeemed in store. If those can be tracked (maybe via custom events or manual input of results), ACE can display them. Vertical benchmarks might also be shown: e.g. “Your response rate 1.0% vs Industry avg ~0.8% for similar campaigns.” This likely is aspirational, not MVP, but something to consider.
Multi-campaign Dashboard: On the main Dashboard (covering multiple campaigns or the whole account overview), analytics are a bit more general: - It might show total campaigns sent this month, total pieces mailed, aggregate response rate, etc., as KPI cards. - A chart of “Campaign Performance” summarizing recent campaigns (the redesign plan in the chat outlines a dashboard layout with multiple sections[179][10], including recent campaigns table, etc.). For example, it could list last 5 campaigns with their mail date, size, and response rate or have bars for each campaign’s response. - Possibly quick insights like “Best Campaign: Spring 2025 – 2.0% response” to highlight successes.
Interactive Features: - Date Range Selector: The screenshot hints at 7 Days, 30 Days, 90 Days toggles on the dashboard【13†】. On an overall dashboard, one might filter the analytics to a time window (e.g. last 30 days of activity). - Filtering by Campaign or Client: Org Admins might filter analytics by client (to see how an individual client is doing). - Drill-down: Clicking on a KPI might take you to the list of recipients or events behind it. E.g. clicking “50 Form Submissions” goes to a list of those 50 leads.
Technology: Likely using a chart library like Recharts or Chart.js in the front-end to render graphs[180]. Data is fetched via API endpoints or calculated on the fly. For large data, some aggregation might be done server-side (SQL can compute counts by day etc. relatively easily using GROUP BY on events). Caching might be considered for analytics queries if performance is an issue (especially if repeatedly viewing heavy campaigns).
Data accuracy and updates: - The analytics should update as new events come in (perhaps not live realtime on screen, but if you refresh or if webhooks trigger something to refresh data). - During an ongoing campaign, numbers will climb. After a campaign is done, the numbers become final. - In some cases, data corrections might happen (e.g. a batch failed and was re-mailed later, or an event came in late). The system should handle late events gracefully (they’ll just reflect in metrics when they arrive).
Examples: For a hypothetical campaign: 5,000 mailed, 4,800 delivered, 500 scanned, 50 forms: - Delivery Rate = 96%. - QR/PURL Engagement = 10.4% (500/4800). - Response/Conversion Rate = 1.04% (50/4800). - Perhaps show “Avg time to response: 2 days” if most people responded within 2 days of delivery. - Show that Texas had 20 out of 50 responses (40%, maybe due to campaign targeting). - If A/B test was done, a chart might compare A vs B: e.g. Variant A: 0.8% conv, Variant B: 1.3% conv – indicating B was better.
Displaying to Users: The emphasis is on clarity and actionable insight. The interface likely uses clear labels, maybe tooltips explaining each metric (especially for new users). For example, hovering “Response Rate” might clarify “Percentage of delivered mail recipients who submitted the response form.”
One concept the team may incorporate is funnel visualization: from Delivered -> Viewed -> Submitted, etc. A funnel chart or just the numbers in sequence can highlight drop-off at each stage.
Integration with CRM Analytics: If needed, data can be exported or via API to external analytics systems. But since ACE provides it internally, many clients might rely on these built-in dashboards.
In summary, the Analytics module provides both broad performance overviews and granular details, enabling users to prove the ROI of direct mail and identify areas for improvement. By presenting metrics like delivery and response rates and enabling drill-down into who responded and from where, ACE Engage gives development and product teams the foundation to continuously optimize campaign strategies (for example, focusing on segments with higher engagement or adjusting mail drop timing to improve response rates).
11. Frontend & UI Design Principles
ACE Engage’s frontend is designed with modern B2B SaaS UX principles, aiming for a clean, professional, and intuitive interface that serves both technical and non-technical users. The design is heavily influenced by best-in-class platforms and a cohesive design system.
Design System & Aesthetics: The application adopts a sophisticated color palette to convey trust and energy. The primary brand color is a deep teal-blue, providing a sense of professionalism and stability[181][182]. Accents are in a vibrant coral/orange, used sparingly for call-to-action buttons or highlights to draw attention to important elements (like “Create Campaign” or “Approve” buttons)[181][183]. A range of neutral grays is used for backgrounds, borders, and text to ensure good contrast and readability[183]. Additionally, status colors are defined: a success green for positive status or success messages, warning amber for alerts, and info blue for informational badges[183].
Typography is modern and clean – likely a sans-serif font common in SaaS apps (e.g. something like Inter or Roboto). Font sizes and weights are chosen for clarity; headings stand out but the overall look remains light and not text-dense. The UI uses consistent spacing and large click targets (buttons, inputs) to improve usability and give a less cluttered feel.
Layout & Navigation: The app uses a dashboard-style layout common to B2B SaaS: - A left-hand sidebar navigation lists the main modules (Dashboard, Campaigns, Audiences/Contacts, Analytics, API/Integrations, Settings, etc.)[2]. Icons accompany each section for quick recognition (e.g. a mail icon for Campaigns, a users icon for Audiences). The sidebar is collapsible for more screen real estate if needed. - A top bar includes context selectors and user menu. For example, an Org Admin or Agency Admin might have an organization switcher at top (to toggle between “Client View” vs “Agency View” or between multiple client accounts)[3]. The screenshot and design mention a top bar with perhaps a dropdown to pick the active client company and an indicator of current view (like a “Client View” vs “Admin View” toggle)【13†】. Also on the top bar: notifications icon, help, and the logged-in user’s avatar with a menu (profile, logout, etc.). - The main content area on the right of the sidebar shows the selected module’s pages. This area is designed to be clean and content-focused. For example, the Dashboard page might show a welcome message and some KPI cards and charts, whereas the Campaigns page might show a list or cards of campaigns.
Role-Based Navigation: The UI dynamically shows/hides certain navigation items depending on the user’s role: - Org Admin sees everything, including the “Agency” or “Admin” sections that contain global settings, user management, vendor config, etc. - Agency Admin sees modules relevant to managing their clients (Campaigns, Audiences, Analytics) and likely an “Agency” section for managing their agency’s info and client list, but not internal-only sections. - Client User sees just the core modules (Campaigns, Audiences, Analytics) for their data, and possibly a simplified navigation without any agency or multi-client context. They likely won’t see the API/Integrations section unless the product allows clients to use API (which it might, if a client wants to integrate their own website to our webhooks). - The design system includes subtle UI hints for roles – for instance, perhaps labels like “Demo Roofing Company Overview” on Dashboard to remind the user what client context they are in (as seen in the screenshot)【13†】. If a user has access to multiple clients, the UI ensures it's clear which client’s data is being viewed at any time (to avoid confusion).
Inspiration & Style: The interface draws inspiration from platforms like Lob (which is a modern direct mail API service), Mailchimp’s campaign builder (familiar to marketers), and “modern SaaS tools like Linear and Stripe”[184]. This means: - A focus on minimalist design: no overly decorative elements, mostly flat design with maybe slight shadows for depth. - Responsive design: The app works on various screen sizes, likely using a fluid grid for forms and tables. So a user could check campaign stats on a tablet or laptop with equal ease. - Smooth interactions: Transitions and micro-interactions are present, e.g. a slide-out panel for viewing details, hover states on cards, smooth modals for forms. - Dark/Light Theme: Indications are that a dark mode is considered (the chat shows an effort to implement a full dark theme)[185][186]. So the design system likely defines both light and dark variations of colors (with background and card colors drastically different, etc.). A theme toggle (sun/moon icon) in the top bar allows switching between light and dark mode, providing user preference support.
Usability Principles: The UI is built to make complex tasks (like launching a direct mail campaign with data and design considerations) as step-by-step as possible: - Wizards & Multi-Step Forms: Creating a campaign is broken into steps (Details -> PURL Settings -> etc.)[11] so as not to overwhelm the user with one giant form. The wizard includes contextual help (like showing a preview of a PURL format or a thumbnail of the selected template). - Validation & Feedback: Form fields validate as the user inputs (e.g., an email field in a manual add recipient form will show an error if not a valid email format; required fields have clear indicators). Upon actions like file import, the UI provides immediate feedback on progress and any errors (in a table format for row errors)[187]. - Calls to Action: Important actions use the accent color (coral/orange) to stand out. Secondary actions are more neutral. The “Approve” button in the proof stage, for example, might be brightly colored to encourage the user to click when ready. - Accessibility: Likely adheres to accessibility standards (using proper contrast for text, keyboard navigability, etc.) – important for enterprise software. - Consistency: The same design language is applied across modules. For instance, tables have the same style (header style, row hover), buttons have a consistent shape (rounded corners as per design radius variables – e.g. a large border radius of 1rem for modern feel[188]). Icons are from a coherent set.
Frontend Tech Stack: While not explicitly stated, given modern patterns it’s likely built with React (the presence of things like useDashboardData.ts in chat logs suggests React + perhaps a state management or hooks pattern)[189]. The team used TypeScript for reliability (the chat mentions fixing TypeScript errors after a DB migration)[190]. They likely use a component library or design system framework (maybe something like Chakra UI or custom built components styled according to the design system).
Example Screens:
  
ACE Engage UI – Sidebar Navigation and Modules.
Image: The left navigation (branded “Mobul ACE” in this instance) shows core sections: Dashboard, Contacts (Audiences) with submenus for All Contacts, Lists & Segments, Import; Campaigns with submenus for All Campaigns, Mail, Landing Pages, Forms. This reflects a logical grouping of features and indicates where a user would navigate to manage contacts vs launch mail vs design landing pages.
As shown above, the sidebar groups features: “Contacts” includes managing lists & segments, “Campaigns” includes everything to do with mailing and the associated landing pages and forms. This grouping helps users find functions intuitively (for example, it's logical that Landing Pages and Forms are under Campaigns, since they are part of campaign response flow). The UI labels may use more familiar terms for clients (e.g. “Contacts” instead of “Audiences”) if that’s more easily understood.
Modern B2B UX considerations: - Many users might be marketing folks or account managers, not engineers, so the UI avoids technical jargon. For example, say "Mail List" instead of "Audience" on some screens, or "Prospects" instead of "Lead Purchase" if that resonates more – this can be adjusted via user feedback. - Onboarding Guidance: A new user sees perhaps a set of checklist or tips (like “You’ve completed all onboarding steps. You’re ready to launch your first campaign!” as in the screenshot banner)【13†】. This friendly guidance helps first-time users know what to do next. - Contextual Help & Tooltips: Little “?” icons or tooltips exist next to complex settings (like what is UTM_campaign, or what does “Hosted Bridge Page” mean) to educate users inline rather than them needing to consult a manual. - Confirmation & Safety: Because sending direct mail incurs cost, the UI likely has confirmation dialogs for critical actions (e.g. submitting campaign to print “Are you sure? This will send X,XXX postcards and incur cost $Y.YY – confirm”). Similarly deleting an audience or campaign asks to confirm, to prevent accidental data loss[191].
Performance and Feedback: The frontend uses spinners/progress bars for longer tasks. When importing, a progress bar shows upload progress and processing status[192][193]. When generating PURLs, a progress indicator shows. If something fails, error messages are displayed in a non-technical, clear way (e.g., “File format not recognized” instead of a stack trace).
Mobile/Tablet Use: While most users likely use the platform on desktops, the responsive design should allow at least viewing stats and perhaps minor actions on tablet. Complex actions like designing a template might be desktop-only experiences due to screen space needed.
In summary, ACE Engage’s frontend follows a “Lovable” design ethos – meaning it strives to be user-friendly and even delightful. By leveraging a coherent design system (teal-blue and coral theme, consistent typography and spacing) and modern UI patterns (sidebar navigation, cards, modals, wizards), it ensures that the development team’s work produces an app that users find familiar and easy to adopt. The UI not only looks professional (instilling confidence in the platform’s reliability)[194] but is also streamlined to let users accomplish their tasks with minimal friction, reflecting the team's knowledge of contemporary B2B SaaS UX.
12. Developer Workflow, Deployment, and Validation Best Practices
Building and maintaining ACE Engage requires careful attention to development process, deployment considerations, and data validation to ensure quality and reliability. This section provides guidance and best practices for developers working on the platform.
Development Workflow: - The project is structured to allow iterative, phased development. The team has a roadmap of features (broken into prompts/phases as in the design chat)[195]. It’s best to tackle features in logical order since many build on each other (e.g. set up Auth & RLS first, then audiences, then campaigns, etc.). Following the planned sequence ensures foundational aspects (like security) are in place early[196]. - Version Control & Code Reviews: All changes should be committed to the repository (likely multiple repos: one for frontend, one for backend/edge functions, one for database migrations if separate). Use feature branches for significant features and open pull requests for peer review. This catches issues early and maintains code quality. - Testing: After implementing each major feature or phase, perform a comprehensive test: - Unit tests for any complex logic (if applicable; e.g. functions that generate tokens or handle form submissions). - Integration tests for API endpoints (ensuring they obey RLS and return expected data). - Manual testing via the UI to simulate user flows. The chat’s “Testing Checklist” is a good reference: verify database tables and RLS, UI components, form validations, edge function outputs, and role-based restrictions after each phase[197]. - Staging Environment: Before deploying to production, have a staging setup where new code and migrations run against a staging database. Use sample data to ensure features like import, campaign submission, and webhooks work in an environment similar to prod. - Secrets & Config: Manage API keys (for vendors, Stripe, etc.) via a secure secrets manager (the platform’s mention of secrets management implies this)[4]. Developers should not hardcode secrets in code. Different environments (dev/staging/prod) will have different keys, so ensure configuration can switch accordingly. - Lovable Cloud / Supabase Dev Tools: The platform uses something akin to Supabase (with auth, storage, etc.). Use migrations or the provided dashboard to manage schema changes. If using Lovable Cloud’s migration capabilities, ensure any auto-generated SQL (as seen in chat) is checked into code if possible (maybe via an .sql files or via a CLI tool). - Edge Functions Debugging: Logging is crucial. Use console.log generously in edge functions for key steps (especially for things like simulate-mail-tracking or purchase-leads) to debug flows. In production, route these logs appropriately (or use a logger that can be turned off or to a file).
Deployment Considerations: - Infrastructure: The app likely runs in a serverless environment. Database is cloud-hosted Postgres with RLS. Edge Functions might be deployed to something like a Cloudflare Workers or Vercel Functions (if Lovable Cloud abstracts it). Ensure that migrations are run before deploying code that depends on them. E.g., if a new table or column is added (like adding deleted_at to tables for soft deletes), run the migration and test queries in staging because RLS might need adjustments. - Zero-Downtime Deploys: If deploying updates to database and functions, be mindful to not break running processes. For example, if you change a table name or column, update related code in one deploy and consider backward compatibility for any in-flight operations. Use feature flags if needed to dark-launch features (though likely not too critical in early stage with fewer users). - Scaling: With potentially large imports and events, monitor database performance. Add indexes where needed (the design already pointed out some indexes on recipients.token etc.)[7]. Ensure any heavy aggregations in analytics either use indexed fields or pre-computed values. For instance, computing metrics for a large campaign on the fly might be slow; consider materialized views or caching if needed (perhaps not at MVP). - File Storage: Ensure the storage bucket (for QR codes, templates thumbnails, etc.) has proper read permissions for what needs to be public (e.g. maybe QR codes are not public, but since they’re included in printed piece, it’s okay if someone could fetch them via URL if they guess it – still, use unguessable names or require auth for private files). - Email Sending: Not mentioned much, but if the system sends emails (like invite users, or notify on form submission), configure a transactional email service and keep templates in config. Verify email deliverability (use verified sender domains, etc.).
Data Validation Best Practices: - On Import: As detailed before, validate presence and format of critical fields[82][105]. Trim whitespace, standardize letter case for states, etc. Use regex or libraries for email/phone format if capturing those. Consider using an address validation API for better accuracy (post-MVP). - On Manual Input: Do client-side validation (e.g., required fields cannot be empty) and server-side (in case someone bypasses UI or for API input) – e.g., the edge function that inserts manual recipients double-checks required fields. - Prevent Duplicates: If same contact appears twice in an upload, decide whether to merge or list separately. Current approach logs and removes duplicates[198]. Use a combination of name+address or a unique donor ID if provided to identify duplicates. - Campaign Validation: Before allowing a campaign to move to "approved", ensure all parts are present. E.g., check that an audience is attached and has >0 valid recipients, a template is selected, mail date is set (or defaulted), and PURL configuration is done. The UI likely ensures these through required steps, but the backend should also enforce (e.g., the submit-to-vendor function might check status == approved and maybe that recipients count > 0). - API Input Validation: When exposing endpoints, validate the payloads. For instance, on POST /v1/campaigns, verify that the template_id and audience_id exist and belong to the client making the request, that the size string is one of allowed values, etc., returning clear error messages for invalid input. - Webhooks & Security: Validate that external payloads (like if we ever accept webhooks from Stripe or USPS) are actually from those sources (check signatures, etc.). Conversely, when sending webhooks, ensure to sign them and possibly limit payload size to avoid overwhelming client. - Edge Cases: Think through edge cases such as: - What if a user tries to submit a campaign twice? (The function should either prevent second submission or handle it idempotently). - If an audience is deleted that was linked to a draft campaign, what happens? Ideally prevent deletion or warn. - If two users concurrently edit the same campaign (not highly likely, but could happen in an agency), last save wins or implement a locking mechanism. - If the print vendor is down or returns an error – the submit function should handle gracefully (set campaign back to approved and show an error message "Submission failed, try again later", log error).
Continuous Improvement: - After each release, gather feedback from actual use. Maybe some form fields need to be added (e.g., maybe clients want to track “donation amount” on the form – then we’d extend leads table). - Keep an eye on actual data: e.g., if many addresses come in invalid, perhaps integrate USPS address verification sooner. Or if many duplicates slip through, tighten duplicate criteria. - Similarly, monitor performance: if imports of 200k take too long, consider optimizing (maybe switching to COPY command if using direct DB access, etc.).
Compliance & Privacy: - With personal data in the system, comply with privacy regulations. For example, have a way to delete a person’s data if requested (GDPR “right to be forgotten”). Soft delete and data retention policies help here[40]. - Only Org Admins (internal) should be able to export full recipient lists with PII; if client users can export their data, that’s fine, but ensure audit logging captures it[146]. - Mask or restrict certain data in UI for roles that shouldn’t see it. Perhaps an Agency Admin can’t see individual names of a client’s donors if not needed (depending on agreements). Probably they can, but just consider if any role-based data hiding is required beyond navigation.
Collaboration: - The development team should maintain good documentation (like this reference manual) and update it as features evolve. This ensures new developers or stakeholders have an accurate picture of system behavior. - Use project management tools to track tasks (the prompt breakdown can be turned into tickets or epics).
Deployment Frequency: - Use an agile approach: deploy incremental improvements frequently rather than big-bang. The API-first nature means frontend and external users rely on API stability, so once in production, avoid breaking API changes. If you need to change an endpoint, consider versioning (keep /v1 stable, introduce /v2 for big changes). - Similarly, database changes should ideally be additive (e.g., adding new fields) rather than destructive changes to avoid downtime.
By adhering to these best practices, the development team will maintain a high-quality codebase and ensure the platform remains robust, secure, and easy to modify. ACE Engage’s complexity (multi-role, multi-module, external integrations) requires diligence in testing and validating at every stage, but the architecture laid out – combined with a thoughtful workflow – positions the team to deliver a reliable product that can be confidently iterated and scaled.
________________


[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] [31] [32] [33] [34] [35] [36] [37] [38] [39] [40] [41] [42] [43] [44] [45] [46] [47] [48] [49] [50] [51] [52] [53] [54] [55] [56] [57] [58] [59] [60] [61] [62] [63] [64] [65] [66] [67] [68] [69] [70] [71] [72] [73] [74] [75] [76] [77] [78] [79] [80] [81] [82] [83] [84] [85] [86] [87] [88] [89] [90] [91] [92] [93] [94] [95] [96] [97] [98] [99] [100] [101] [102] [103] [104] [105] [106] [107] [108] [109] [110] [111] [112] [113] [114] [115] [116] [117] [118] [119] [120] [121] [122] [123] [124] [125] [126] [127] [128] [129] [130] [131] [132] [133] [134] [135] [136] [137] [138] [139] [140] [141] [142] [143] [144] [145] [146] [147] [148] [149] [150] [151] [152] [153] [154] [155] [156] [157] [158] [159] [160] [161] [162] [163] [164] [165] [166] [167] [168] [169] [170] [171] [172] [173] [174] [175] [176] [177] [178] [179] [180] [181] [182] [183] [184] [185] [186] [187] [188] [189] [190] [191] [192] [193] [194] [195] [196] [197] [198] lovable-chat-2025-11-26T18-06-22.txt
file://file_00000000820471fdb953e234c552a7f4